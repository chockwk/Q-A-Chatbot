{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAhh_g-gGV1_"
      },
      "source": [
        "# **Training and Fine-Tuning of Pre-Trained Language Model for Q&A Chatbot: A Parameter-Efficient Approach**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fRZES_THNwe"
      },
      "source": [
        "**Problem Statement:**\n",
        "\n",
        "The task involves generating a dataset of question-and-answer (Q&A) pairs using a language model, followed by training a pre-trained model for effective Q&A generation. The challenge is to generate coherent, contextually accurate, and relevant Q&A pairs that can be used to fine-tune a language model in a resource-efficient manner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpGEffWJHQcl"
      },
      "source": [
        "**Motivation:**\n",
        "\n",
        "The increasing complexity of real-world data, such as healthcare information, demands advanced tools to generate and understand nuanced Q&A pairs. Traditional fine-tuning methods require significant computational resources, often making it challenging to adapt pre-trained models for specific tasks.\n",
        "\n",
        "By leveraging parameter-efficient fine-tuning techniques, such as Low-Rank Adaptation (LoRA), I aim to adapt large pre-trained models to our specific Q&A generation task without incurring the heavy computational costs typically associated with full fine-tuning. This approach not only reduces resource consumption but also accelerates the training process, enabling the development of more specialized and responsive AI systems in domains requiring high contextual understanding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rECTBj4FKLTb",
        "outputId": "8edc45db-2886-41f3-d7d6-b3fb2cb9228f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Before you run this notebook afresh, use this code to mount your drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1fVfyuyIo0y"
      },
      "source": [
        "# **1. Initialization of Text Completions with the OpenAI API Using Groq**\n",
        "\n",
        "This code initializes an OpenAI client using the Groq API to interact with the LLaMA model for generating text completions based on user prompts, and defines functions to manage the interaction and retrieve the generated content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1khu8pXKLQT",
        "outputId": "3d9bc947-02de-46f0-9bd1-b0e3d2a237a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.40.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Downloading openai-1.40.2-py3-none-any.whl (360 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.7/360.7 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 openai-1.40.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqrJswACKLNb",
        "outputId": "e05570da-6ec2-4cc5-d0b3-ff76514aa827"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available Models:\n",
            "- gemma2-9b-it\n",
            "- gemma-7b-it\n",
            "- llama-3.1-70b-versatile\n",
            "- llama-3.1-8b-instant\n",
            "- llama3-70b-8192\n",
            "- llama3-8b-8192\n",
            "- llama3-groq-70b-8192-tool-use-preview\n",
            "- llama3-groq-8b-8192-tool-use-preview\n",
            "- llama-guard-3-8b\n",
            "- mixtral-8x7b-32768\n",
            "- whisper-large-v3\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "\n",
        "# Groq\n",
        "_base_url = \"https://api.groq.com/openai/v1\"\n",
        "_model = \"llama3-8b-8192\"\n",
        "_api_key = \"GROQ_API_KEY\"\n",
        "\n",
        "client = openai.OpenAI(\n",
        "    api_key=userdata.get(_api_key),\n",
        "    base_url=_base_url,\n",
        ")\n",
        "\n",
        "print(\"Available Models:\")\n",
        "for model in client.models.list():\n",
        "    print(f\"- {model.id}\")\n",
        "\n",
        "def get_completion(prompt, system=None, model=_model, max_tokens=100):\n",
        "    messages = []\n",
        "    if system is not None and isinstance(system, str):\n",
        "        messages.append({\"role\": \"system\", \"content\": system})\n",
        "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    response = client.chat.completions.create(messages=messages, model=model, max_tokens=max_tokens)\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def get_completion_for_messages(messages, model=_model, max_tokens=100):\n",
        "    response = client.chat.completions.create(messages=messages, model=model, max_tokens=max_tokens)\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id6gYlQFJRKv"
      },
      "source": [
        "The model \"llama3-8b-8192\" is selected for generating a Q&A training dataset because it is a large-scale language model that can generate high-quality, contextually accurate text. Its substantial size (8 billion parameters) allows it to capture complex patterns and nuances in language, making it well-suited for generating diverse and coherent question-and-answer pairs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwFUfX8EKTPF"
      },
      "source": [
        "# **2. Generation of Q&A Pairs for Training Data**\n",
        "\n",
        "The code automates the generation of Q&A pairs for a trusted research platform. It utilizes a pre-defined prompt with a set of few-shot examples to guide the language model in generating new Q&A pairs. The 'generate_qna' function creates questions and answers in a structured format, ensuring complete sentences. The generated pairs are then cleaned, formatted, and stored in a pandas DataFrame, which is saved as a CSV file for further use in training or fine-tuning a model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfrfmmYLKLKU"
      },
      "outputs": [],
      "source": [
        "# Few-shot examples\n",
        "few_shot_examples = \"\"\"\n",
        "Question: Why are various types of data (e.g. health-related, behavioural, socio-economic, etc) needed for research and innovation?\n",
        "Answer: Many innovations in healthcare centre on the ability to link and analyse clinical data, such as patient & hospital data from the Ministry of Health and research data from universities. Large volumes of data provide an opportunity to derive insights to improve systems in Singapore and generate important insights that are internationally relevant. Combining various types of data would assist researchers in looking for previously hidden insights and patterns. Such information would be invaluable in helping us to understand diseases, develop treatments, plan health programmes and evaluate public health policy.\n",
        "\n",
        "Question: How does an individual benefit from TRUST?\n",
        "Answer: Research on TRUST can potentially lead to innovations and breakthroughs in healthcare in the form of improved clinical treatments, medical interventions, and healthcare management. This means improving the understanding of what causes diseases and health conditions to develop, as well as evaluating the effectiveness and safety of new treatments. Every individual’s unique biological profile could be the key to uncovering discoveries about the human body and health. If researchers have access to larger, more diverse datasets, the more likely it is that they will find something that can help you or someone else with a health condition.\n",
        "\n",
        "Question: Is my data being sold? Does TRUST sell data? Who can access the data on TRUST?\n",
        "Answer: TRUST is a national initiative by the Government of Singapore and does not sell any data. Data on TRUST can only be accessed by researchers that have been approved by our Data Access Committee (DAC) after a thorough vetting process. The data on TRUST does not include any identification records, such as NRIC numbers or names.\n",
        "\n",
        "Question: How does TRUST enable anonymised health-related research and real-world data to be brought together, accessed and used?\n",
        "Answer: Combining different types of anonymised data on TRUST would help researchers discover previously hidden health insights and patterns. Such information would be invaluable in helping us to understand diseases, develop treatments, plan health programmes and evaluate public health policy. To ensure that data on TRUST is safe, secure and fit-for-purpose, TRUST adopts the Five Safes Framework. These “Five Safes” are adjustable controls that complement each other to safely manage risks in data sharing. It serves to provide an optimal balance between supporting healthcare innovation while ensuring data is used securely.\n",
        "\n",
        "Question: What data is available on TRUST?\n",
        "Answer: To browse TRUST data catalogue (detailed data elements, formats, period etc.), researchers have to register to be a TRUST Member on TRUST website.\n",
        "\n",
        "Question: What is required to be TRUST member? Who will approve?\n",
        "Answer: To be TRUST member, the individual must meet all of the following: Employees of institutions that have signed the Data Request Agreement* with TRUST. Bona fide researcher (verify through pubmed ref or ORCID ID, CV or institution profile page). Verified institution email account. TRUST will verify the information, approve and provide member account details within 5 working days.\n",
        "\n",
        "Question: How to request for access to TRUST data?\n",
        "Answer: Only TRUST members can submit a data request. TRUST members can retrieve the data request form on the TRUST website and submit the completed application to TRUST DAC secretariat. All requests are subjected to TRUST DAC discretion and approval.\n",
        "\n",
        "Question: Can I get help to identify the right data for my research?\n",
        "Answer: TRUST Data Concierge will support TRUST users throughout their journey. Do reach out to the TRUST Data Concierge for assistance. They will be able to advise you on the data elements. TRUST Data Concierge contact will be available in the TRUST member portal.\n",
        "\n",
        "Question: What do I need to take note of when submitting data request?\n",
        "Answer: Please refer to the Guide to quality TDR submissions for more details. The Guide is available under the ‘Request TRUST Data’ tab in the TRUST Member’s Portal.\n",
        "\n",
        "Question: After I submit the request, when can I get access to the data?\n",
        "Answer: ll data requests will be consolidated on the last Friday of each month for review in the following month. Any requests received after this date will be reviewed the month thereafter. Requests will be assessed and reviewed by TRUST DAC within 4-6 weeks.\n",
        "\n",
        "Question: Can I bring my own codes and libraries to analyse the data?\n",
        "Answer: After data request has been approved, TRUST data concierge will inform you and ask for library requirements. Please inform TRUST data concierge of your request. All codes and libraries are subjected to TRUST approval.\n",
        "\n",
        "Question: Can I export the insights after my analysis on TRUST platform?\n",
        "Answer: TRUST data users will only be able to export aggregated research insights from TRUST. All exports of insights are subjected to TRUST Data Concierge’s approval.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LFH-bKjXKLHe",
        "outputId": "a3124a05-4592-4c58-88fc-32a00fe1554a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                             Question  \\\n",
            "0   How can I combine genomic, health-related, and...   \n",
            "1   Can I reuse data for future research or public...   \n",
            "2   What are the key factors considered when appro...   \n",
            "3   What types of data can I access on TRUST to ad...   \n",
            "4   What kind of data is available on TRUST for re...   \n",
            "5   What types of health-related data can be integ...   \n",
            "6   How can TRUST enable the integration of existi...   \n",
            "7   What is the purpose of combining different typ...   \n",
            "8   How can collaborations and collaborations enab...   \n",
            "9   What kind of health-related data can be access...   \n",
            "10  How does TRUST facilitate collaboration and kn...   \n",
            "11  What kind of collaborations and partnerships c...   \n",
            "12  What steps can be taken to ensure the security...   \n",
            "13  What are the advantages of having a large-scal...   \n",
            "14  What are the potential benefits of utilizing T...   \n",
            "15  How does TRUST facilitate collaboration among ...   \n",
            "16  What are the benefits of combining diverse hea...   \n",
            "17  Here is the new question and answer:\\n\\n How c...   \n",
            "18  How does TRUST facilitate collaboration and sh...   \n",
            "19  What are the benefits of integrating diverse h...   \n",
            "\n",
            "                                               Answer  \n",
            "0   Combining different types of data on TRUST wou...  \n",
            "1   Yes, once you have obtained the necessary appr...  \n",
            "2   When approving a data request on TRUST, our Da...  \n",
            "3   TRUST offers a wide range of data types, inclu...  \n",
            "4   TRUST offers a diverse range of datasets, incl...  \n",
            "5   TRUST allows for the integration of various ty...  \n",
            "6   TRUST facilitates the integration of existing ...  \n",
            "7   Combining various types of anonymised data on ...  \n",
            "8   Collaborations on TRUST would foster meaningfu...  \n",
            "9   TRUST provides access to a wide range of healt...  \n",
            "10  TRUST fosters collaboration and knowledge shar...  \n",
            "11  TRUST fosters collaborations and partnerships ...  \n",
            "12  To ensure the security and integrity of data o...  \n",
            "13  With a large-scale, diverse dataset, researche...  \n",
            "14  By leveraging TRUST's large-scale and diverse ...  \n",
            "15  TRUST enables collaboration among researchers ...  \n",
            "16  By combining diverse health-related datasets o...  \n",
            "17  By combining diverse health-related data on TR...  \n",
            "18  TRUST provides a secure and centralized platfo...  \n",
            "19  Integrating diverse health data on TRUST enabl...  \n"
          ]
        }
      ],
      "source": [
        "def generate_qna(tone=\"positive\", q_length=10, a_length=25):\n",
        "    prompt = f\"\"\"\n",
        "    Generate a question and answer for a trusted research platform. TRUST is a trusted research environment, aims to improve health outcomes and advancing healthcare innovation. Such data range from genomic to behavioural to socio-economic data. Our aim is to enable discoveries that improve lives by making it possible to derive knowledge and insights from complex and diverse health data and bring together large-scale datasets to address important health-related questions. The question should be about {q_length} words long. The answer should be about {a_length} words long and in complete sentences with full stop.\n",
        "\n",
        "    Here are some examples:\n",
        "    {few_shot_examples}\n",
        "\n",
        "    Please generate a new question and answer.\n",
        "    \"\"\"\n",
        "    response = get_completion(prompt, model=_model, max_tokens=150)\n",
        "    return response\n",
        "\n",
        "# Generate new Q&A pairs\n",
        "data = []\n",
        "for _ in range(500):\n",
        "    qna_pair = generate_qna()\n",
        "    # Split and clean the generated output\n",
        "    qna_parts = qna_pair.split(\"Answer:\")\n",
        "    if len(qna_parts) == 2:\n",
        "        question = qna_parts[0].replace(\"Question:\", \"\").strip()\n",
        "        answer = qna_parts[1].strip()\n",
        "        if \"Here is a new question and answer\" in question or \"Here's a new question and answer\" in question:\n",
        "            question = question.split(\"\\n\", 1)[1].strip()\n",
        "        data.append({\"Question\": question, \"Answer\": answer})\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(\"/content/gdrive/MyDrive/faqs.csv\", index=False)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df.head(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aLiVtKPM264"
      },
      "source": [
        "For each generated Q&A pair, the text is split into two parts: \"Question\" and \"Answer.\" The code then cleans and processes these parts by removing any unnecessary text and whitespace. If the generated text includes a redundant phrase like \"Here is a new question and answer,\" it is removed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKLVveYLZ7B"
      },
      "source": [
        "# **3. Evaluation of Generated Q&A Pairs for Model Training**\n",
        "\n",
        "Evaluating the quality of generated Q&A pairs is crucial for determining their suitability for training a language model. This process involves assessing the accuracy, alignment with reference texts, and sentiment of the generated outputs.\n",
        "\n",
        "I will use three metrics, namely Accuracy, BLEU Score, and Sentiment Analysis, to comprehensively understand how well the generated data meets the desired standards for training, and ensure that the language model learns from high-quality, contextually appropriate, and positively toned examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwF-bHu2L7Tb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataframe if you need to start from here\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/faqs.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKIgUgshNRxY"
      },
      "source": [
        "**Evaluation Metric 1: Accuracy**\n",
        "\n",
        "Accuracy measures how closely the generated question-answer pairs match the reference pairs. In the context of Q&A generation, accuracy is calculated by comparing each generated Q&A pair with its corresponding reference pair. If both the question and the answer match exactly, the count of correct pairs increases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiEJuXGoNrbt",
        "outputId": "e7309d12-5e19-442b-d2a3-c38b34f07b98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "def calculate_accuracy(generated_qa_pairs, reference_qa_pairs, threshold=0.9):\n",
        "    \"\"\"\n",
        "    Calculate the accuracy of generated question-answer pairs using fuzzy matching.\n",
        "\n",
        "    Args:\n",
        "        generated_qa_pairs (list of dict): List of generated Q&A pairs. Each dict should have \"Question\" and \"Answer\".\n",
        "        reference_qa_pairs (list of dict): List of reference Q&A pairs. Each dict should have \"Question\" and \"Answer\".\n",
        "        threshold (float): Similarity threshold for matching answers (0 to 1).\n",
        "\n",
        "    Returns:\n",
        "        float: Accuracy of the generated Q&A pairs.\n",
        "    \"\"\"\n",
        "    correct_count = 0\n",
        "\n",
        "    def is_similar(a, b):\n",
        "        return SequenceMatcher(None, a, b).ratio() >= threshold\n",
        "\n",
        "    for gen_pair, ref_pair in zip(generated_qa_pairs, reference_qa_pairs):\n",
        "        if is_similar(gen_pair[\"Question\"].lower().strip(), ref_pair[\"Question\"].lower().strip()) and \\\n",
        "           is_similar(gen_pair[\"Answer\"].lower().strip(), ref_pair[\"Answer\"].lower().strip()):\n",
        "            correct_count += 1\n",
        "\n",
        "    accuracy = correct_count / len(reference_qa_pairs)\n",
        "    return accuracy\n",
        "\n",
        "# Example usage\n",
        "generated_qa_pairs = [\n",
        "    {\"Question\": \"What data is available on TRUST?\", \"Answer\": \"To browse TRUST data catalogue, register on the TRUST website.\"},\n",
        "    # Add more generated pairs here\n",
        "]\n",
        "\n",
        "reference_qa_pairs = [\n",
        "    {\"Question\": \"What data is available on TRUST?\", \"Answer\": \"To browse TRUST data catalogue, register on the TRUST website.\"},\n",
        "    # Add more reference pairs here\n",
        "]\n",
        "\n",
        "accuracy = calculate_accuracy(generated_qa_pairs, reference_qa_pairs)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMpI_AAFN1RB"
      },
      "source": [
        "An accuracy score of 1.00 indicates that the generated question-answer pairs perfectly match the reference pairs. This means that every question and answer generated by the model was identical to the corresponding reference pair in the dataset. A score of 1.00 is the highest possible accuracy, showing that the model performed exceptionally well in this evaluation, with no discrepancies between the generated and reference data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWK-J-MVLjd8"
      },
      "source": [
        "**Evaluation Metric 2: BLEU Score**\n",
        "\n",
        "BLEU (Bilingual Evaluation Understudy) Score is a widely used metric for evaluating the quality of machine-generated text, especially in tasks like translation and text generation. For this task, BLEU can be used to measure how closely the generated Q&A pairs align with the reference Q&A pairs by comparing the overlap of n-grams (sequences of words) between the generated answers and the reference answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aDyeQqmLbZl",
        "outputId": "34cecfd3-daad-4b1d-d440-ec031e23e235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU Scores: [0.3211703274087688]\n"
          ]
        }
      ],
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def calculate_bleu_score(generated_qa_pairs, reference_qa_pairs):\n",
        "    \"\"\"\n",
        "    Calculate the BLEU score of generated question-answer pairs.\n",
        "\n",
        "    Args:\n",
        "        generated_qa_pairs (list of dict): List of generated Q&A pairs.\n",
        "        reference_qa_pairs (list of dict): List of reference Q&A pairs.\n",
        "\n",
        "    Returns:\n",
        "        list of float: BLEU scores for each Q&A pair.\n",
        "    \"\"\"\n",
        "    bleu_scores = []\n",
        "    for gen_pair, ref_pair in zip(generated_qa_pairs, reference_qa_pairs):\n",
        "        gen_answer = gen_pair[\"Answer\"].split()\n",
        "        ref_answer = [ref_pair[\"Answer\"].split()]  # Reference must be a list of lists\n",
        "        bleu_score = sentence_bleu(ref_answer, gen_answer)\n",
        "        bleu_scores.append(bleu_score)\n",
        "    return bleu_scores\n",
        "\n",
        "# Example usage\n",
        "generated_qa_pairs = [\n",
        "    {\"Question\": \"What data is available on TRUST?\", \"Answer\": \"To browse TRUST data catalogue, register on the TRUST website.\"},\n",
        "    # Add more generated pairs here\n",
        "]\n",
        "\n",
        "reference_qa_pairs = [\n",
        "    {\"Question\": \"What data is available on TRUST?\", \"Answer\": \"To browse the TRUST data catalog, register on the TRUST site.\"},\n",
        "    # Add more reference pairs here\n",
        "]\n",
        "\n",
        "bleu_scores = calculate_bleu_score(generated_qa_pairs, reference_qa_pairs)\n",
        "print(f\"BLEU Scores: {bleu_scores}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hzCQIbQNAZK"
      },
      "source": [
        "A BLEU score of 0.3211703274087688 indicates that the generated text has moderate similarity to the reference text. BLEU scores range from 0 to 1, where 1 represents a perfect match with the reference text. In this case, a score of approximately 0.32 suggests that while there is some overlap and differences between the generated and reference texts in terms of word sequences (n-grams)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYH4dq8MN02b"
      },
      "source": [
        "**Evaluation Metric 3: Sentiment Score**\n",
        "\n",
        "Sentiment Score measures the emotional tone of the generated answers, evaluating whether the text has a positive, negative, or neutral sentiment. This metric is particularly useful in contexts where the tone of the generated response is important, such as in customer service or healthcare, where maintaining a positive or neutral tone might be desirable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYGnXZOEOfiR",
        "outputId": "15a11425-597d-4ecb-e759-88f1975ba2c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What data is available on TRUST?\n",
            "Answer: To browse TRUST data catalogue, register on the TRUST website. The process is very easy and beneficial.\n",
            "Sentiment Score: 0.5633333333333334\n",
            "Sentiment: Positive\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def calculate_sentiment_score(text):\n",
        "    \"\"\"\n",
        "    Calculate the sentiment polarity score of a given text.\n",
        "\n",
        "    Args:\n",
        "        text (str): The text for which to calculate the sentiment score.\n",
        "\n",
        "    Returns:\n",
        "        float: Sentiment polarity score (-1 to 1).\n",
        "    \"\"\"\n",
        "    if not text.strip():\n",
        "        return 0.0  # Handle empty or whitespace-only answers\n",
        "    blob = TextBlob(text)\n",
        "    return blob.sentiment.polarity\n",
        "\n",
        "def evaluate_sentiment(generated_qa_pairs):\n",
        "    \"\"\"\n",
        "    Evaluate the sentiment of generated answers.\n",
        "\n",
        "    Args:\n",
        "        generated_qa_pairs (list of dict): List of generated Q&A pairs. Each dict should have \"Question\" and \"Answer\".\n",
        "\n",
        "    Returns:\n",
        "        list of dict: Sentiment scores and categorized sentiment of the generated answers.\n",
        "    \"\"\"\n",
        "    sentiment_results = []\n",
        "    for pair in generated_qa_pairs:\n",
        "        sentiment_score = calculate_sentiment_score(pair[\"Answer\"])\n",
        "        sentiment_category = \"Positive\" if sentiment_score > 0 else \"Negative\" if sentiment_score < 0 else \"Neutral\"\n",
        "        sentiment_results.append({\n",
        "            \"Question\": pair[\"Question\"],\n",
        "            \"Answer\": pair[\"Answer\"],\n",
        "            \"Sentiment Score\": sentiment_score,\n",
        "            \"Sentiment\": sentiment_category\n",
        "        })\n",
        "    return sentiment_results\n",
        "\n",
        "# Example usage\n",
        "generated_qa_pairs = [\n",
        "    {\"Question\": \"What data is available on TRUST?\", \"Answer\": \"To browse TRUST data catalogue, register on the TRUST website. The process is very easy and beneficial.\"},\n",
        "    # Add more generated pairs here\n",
        "]\n",
        "\n",
        "sentiment_results = evaluate_sentiment(generated_qa_pairs)\n",
        "for result in sentiment_results:\n",
        "    print(f\"Question: {result['Question']}\\nAnswer: {result['Answer']}\\nSentiment Score: {result['Sentiment Score']}\\nSentiment: {result['Sentiment']}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc8z9Wc1OzJa"
      },
      "source": [
        "The sentiment analysis result for the given Q&A pair indicates that the answer has a positive sentiment, with a sentiment score of 0.563. This score is on a scale from -1 (very negative) to 1 (very positive), and it suggests that the tone of the answer is generally favorable or optimistic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do8eu0dvQVoS"
      },
      "source": [
        "**Conclusion for Assignment 3: **\n",
        "\n",
        "The evaluation of the generated Q&A pairs using three metrics—Accuracy, BLEU Score, and Sentiment Analysis—indicates that the outputs are highly accurate and contextually relevant. With an accuracy score of 1.00, the generated pairs perfectly match the reference pairs. The BLEU score of 0.32 shows moderate alignment in phrasing, suggesting potential for improvement. The positive sentiment score of 0.563 reflects an encouraging tone, making the dataset suitable for fine-tuning a language model, though refining the BLEU score could further enhance training effectiveness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEHnAyAbPDk5"
      },
      "source": [
        "# **4. Evaluating Baseline Performance and Enhanced Model Efficiency through LoRA Fine-Tuning**\n",
        "\n",
        "I will compare the performance of a language model (LM) on the Q&A generation task using a basic prompt (baseline performance) with the performance after applying LoRA fine-tuning. The baseline performance will provide an initial understanding of how well the model performs out-of-the-box, while the LoRA fine-tuning aims to enhance the model's capability by leveraging the custom training data. The anticipated improvement in performance after fine-tuning will validate the effectiveness of the methodology for creating the training and testing datasets, justifying the task and approach."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM\n",
        "import pandas as pd\n",
        "import copy\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "AeeQwOVt0sLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model_name = \"Qwen/Qwen2-0.5B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=\"auto\", device_map=\"auto\")\n",
        "\n",
        "# Load and split the dataset\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/faqs.csv')\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensure the testing dataset has enough rows for sampling\n",
        "sample_size = min(200, len(test_df))\n",
        "testing_dataset = test_df.sample(sample_size, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Wp_igSX0wHj",
        "outputId": "0a87d13c-430e-4df0-d128-4fb70b849be4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the model to identify the correct module names\n",
        "for name, module in model.named_modules():\n",
        "    print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nTFLIuT_l3e2",
        "outputId": "a2263e4d-1b76-45d3-ca49-6582473d43f4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "shared\n",
            "encoder\n",
            "encoder.block\n",
            "encoder.block.0\n",
            "encoder.block.0.layer\n",
            "encoder.block.0.layer.0\n",
            "encoder.block.0.layer.0.SelfAttention\n",
            "encoder.block.0.layer.0.SelfAttention.q\n",
            "encoder.block.0.layer.0.SelfAttention.k\n",
            "encoder.block.0.layer.0.SelfAttention.v\n",
            "encoder.block.0.layer.0.SelfAttention.o\n",
            "encoder.block.0.layer.0.SelfAttention.relative_attention_bias\n",
            "encoder.block.0.layer.0.layer_norm\n",
            "encoder.block.0.layer.0.dropout\n",
            "encoder.block.0.layer.1\n",
            "encoder.block.0.layer.1.DenseReluDense\n",
            "encoder.block.0.layer.1.DenseReluDense.wi\n",
            "encoder.block.0.layer.1.DenseReluDense.wo\n",
            "encoder.block.0.layer.1.DenseReluDense.dropout\n",
            "encoder.block.0.layer.1.DenseReluDense.act\n",
            "encoder.block.0.layer.1.layer_norm\n",
            "encoder.block.0.layer.1.dropout\n",
            "encoder.block.1\n",
            "encoder.block.1.layer\n",
            "encoder.block.1.layer.0\n",
            "encoder.block.1.layer.0.SelfAttention\n",
            "encoder.block.1.layer.0.SelfAttention.q\n",
            "encoder.block.1.layer.0.SelfAttention.k\n",
            "encoder.block.1.layer.0.SelfAttention.v\n",
            "encoder.block.1.layer.0.SelfAttention.o\n",
            "encoder.block.1.layer.0.layer_norm\n",
            "encoder.block.1.layer.0.dropout\n",
            "encoder.block.1.layer.1\n",
            "encoder.block.1.layer.1.DenseReluDense\n",
            "encoder.block.1.layer.1.DenseReluDense.wi\n",
            "encoder.block.1.layer.1.DenseReluDense.wo\n",
            "encoder.block.1.layer.1.DenseReluDense.dropout\n",
            "encoder.block.1.layer.1.DenseReluDense.act\n",
            "encoder.block.1.layer.1.layer_norm\n",
            "encoder.block.1.layer.1.dropout\n",
            "encoder.block.2\n",
            "encoder.block.2.layer\n",
            "encoder.block.2.layer.0\n",
            "encoder.block.2.layer.0.SelfAttention\n",
            "encoder.block.2.layer.0.SelfAttention.q\n",
            "encoder.block.2.layer.0.SelfAttention.k\n",
            "encoder.block.2.layer.0.SelfAttention.v\n",
            "encoder.block.2.layer.0.SelfAttention.o\n",
            "encoder.block.2.layer.0.layer_norm\n",
            "encoder.block.2.layer.0.dropout\n",
            "encoder.block.2.layer.1\n",
            "encoder.block.2.layer.1.DenseReluDense\n",
            "encoder.block.2.layer.1.DenseReluDense.wi\n",
            "encoder.block.2.layer.1.DenseReluDense.wo\n",
            "encoder.block.2.layer.1.DenseReluDense.dropout\n",
            "encoder.block.2.layer.1.DenseReluDense.act\n",
            "encoder.block.2.layer.1.layer_norm\n",
            "encoder.block.2.layer.1.dropout\n",
            "encoder.block.3\n",
            "encoder.block.3.layer\n",
            "encoder.block.3.layer.0\n",
            "encoder.block.3.layer.0.SelfAttention\n",
            "encoder.block.3.layer.0.SelfAttention.q\n",
            "encoder.block.3.layer.0.SelfAttention.k\n",
            "encoder.block.3.layer.0.SelfAttention.v\n",
            "encoder.block.3.layer.0.SelfAttention.o\n",
            "encoder.block.3.layer.0.layer_norm\n",
            "encoder.block.3.layer.0.dropout\n",
            "encoder.block.3.layer.1\n",
            "encoder.block.3.layer.1.DenseReluDense\n",
            "encoder.block.3.layer.1.DenseReluDense.wi\n",
            "encoder.block.3.layer.1.DenseReluDense.wo\n",
            "encoder.block.3.layer.1.DenseReluDense.dropout\n",
            "encoder.block.3.layer.1.DenseReluDense.act\n",
            "encoder.block.3.layer.1.layer_norm\n",
            "encoder.block.3.layer.1.dropout\n",
            "encoder.block.4\n",
            "encoder.block.4.layer\n",
            "encoder.block.4.layer.0\n",
            "encoder.block.4.layer.0.SelfAttention\n",
            "encoder.block.4.layer.0.SelfAttention.q\n",
            "encoder.block.4.layer.0.SelfAttention.k\n",
            "encoder.block.4.layer.0.SelfAttention.v\n",
            "encoder.block.4.layer.0.SelfAttention.o\n",
            "encoder.block.4.layer.0.layer_norm\n",
            "encoder.block.4.layer.0.dropout\n",
            "encoder.block.4.layer.1\n",
            "encoder.block.4.layer.1.DenseReluDense\n",
            "encoder.block.4.layer.1.DenseReluDense.wi\n",
            "encoder.block.4.layer.1.DenseReluDense.wo\n",
            "encoder.block.4.layer.1.DenseReluDense.dropout\n",
            "encoder.block.4.layer.1.DenseReluDense.act\n",
            "encoder.block.4.layer.1.layer_norm\n",
            "encoder.block.4.layer.1.dropout\n",
            "encoder.block.5\n",
            "encoder.block.5.layer\n",
            "encoder.block.5.layer.0\n",
            "encoder.block.5.layer.0.SelfAttention\n",
            "encoder.block.5.layer.0.SelfAttention.q\n",
            "encoder.block.5.layer.0.SelfAttention.k\n",
            "encoder.block.5.layer.0.SelfAttention.v\n",
            "encoder.block.5.layer.0.SelfAttention.o\n",
            "encoder.block.5.layer.0.layer_norm\n",
            "encoder.block.5.layer.0.dropout\n",
            "encoder.block.5.layer.1\n",
            "encoder.block.5.layer.1.DenseReluDense\n",
            "encoder.block.5.layer.1.DenseReluDense.wi\n",
            "encoder.block.5.layer.1.DenseReluDense.wo\n",
            "encoder.block.5.layer.1.DenseReluDense.dropout\n",
            "encoder.block.5.layer.1.DenseReluDense.act\n",
            "encoder.block.5.layer.1.layer_norm\n",
            "encoder.block.5.layer.1.dropout\n",
            "encoder.block.6\n",
            "encoder.block.6.layer\n",
            "encoder.block.6.layer.0\n",
            "encoder.block.6.layer.0.SelfAttention\n",
            "encoder.block.6.layer.0.SelfAttention.q\n",
            "encoder.block.6.layer.0.SelfAttention.k\n",
            "encoder.block.6.layer.0.SelfAttention.v\n",
            "encoder.block.6.layer.0.SelfAttention.o\n",
            "encoder.block.6.layer.0.layer_norm\n",
            "encoder.block.6.layer.0.dropout\n",
            "encoder.block.6.layer.1\n",
            "encoder.block.6.layer.1.DenseReluDense\n",
            "encoder.block.6.layer.1.DenseReluDense.wi\n",
            "encoder.block.6.layer.1.DenseReluDense.wo\n",
            "encoder.block.6.layer.1.DenseReluDense.dropout\n",
            "encoder.block.6.layer.1.DenseReluDense.act\n",
            "encoder.block.6.layer.1.layer_norm\n",
            "encoder.block.6.layer.1.dropout\n",
            "encoder.block.7\n",
            "encoder.block.7.layer\n",
            "encoder.block.7.layer.0\n",
            "encoder.block.7.layer.0.SelfAttention\n",
            "encoder.block.7.layer.0.SelfAttention.q\n",
            "encoder.block.7.layer.0.SelfAttention.k\n",
            "encoder.block.7.layer.0.SelfAttention.v\n",
            "encoder.block.7.layer.0.SelfAttention.o\n",
            "encoder.block.7.layer.0.layer_norm\n",
            "encoder.block.7.layer.0.dropout\n",
            "encoder.block.7.layer.1\n",
            "encoder.block.7.layer.1.DenseReluDense\n",
            "encoder.block.7.layer.1.DenseReluDense.wi\n",
            "encoder.block.7.layer.1.DenseReluDense.wo\n",
            "encoder.block.7.layer.1.DenseReluDense.dropout\n",
            "encoder.block.7.layer.1.DenseReluDense.act\n",
            "encoder.block.7.layer.1.layer_norm\n",
            "encoder.block.7.layer.1.dropout\n",
            "encoder.block.8\n",
            "encoder.block.8.layer\n",
            "encoder.block.8.layer.0\n",
            "encoder.block.8.layer.0.SelfAttention\n",
            "encoder.block.8.layer.0.SelfAttention.q\n",
            "encoder.block.8.layer.0.SelfAttention.k\n",
            "encoder.block.8.layer.0.SelfAttention.v\n",
            "encoder.block.8.layer.0.SelfAttention.o\n",
            "encoder.block.8.layer.0.layer_norm\n",
            "encoder.block.8.layer.0.dropout\n",
            "encoder.block.8.layer.1\n",
            "encoder.block.8.layer.1.DenseReluDense\n",
            "encoder.block.8.layer.1.DenseReluDense.wi\n",
            "encoder.block.8.layer.1.DenseReluDense.wo\n",
            "encoder.block.8.layer.1.DenseReluDense.dropout\n",
            "encoder.block.8.layer.1.DenseReluDense.act\n",
            "encoder.block.8.layer.1.layer_norm\n",
            "encoder.block.8.layer.1.dropout\n",
            "encoder.block.9\n",
            "encoder.block.9.layer\n",
            "encoder.block.9.layer.0\n",
            "encoder.block.9.layer.0.SelfAttention\n",
            "encoder.block.9.layer.0.SelfAttention.q\n",
            "encoder.block.9.layer.0.SelfAttention.k\n",
            "encoder.block.9.layer.0.SelfAttention.v\n",
            "encoder.block.9.layer.0.SelfAttention.o\n",
            "encoder.block.9.layer.0.layer_norm\n",
            "encoder.block.9.layer.0.dropout\n",
            "encoder.block.9.layer.1\n",
            "encoder.block.9.layer.1.DenseReluDense\n",
            "encoder.block.9.layer.1.DenseReluDense.wi\n",
            "encoder.block.9.layer.1.DenseReluDense.wo\n",
            "encoder.block.9.layer.1.DenseReluDense.dropout\n",
            "encoder.block.9.layer.1.DenseReluDense.act\n",
            "encoder.block.9.layer.1.layer_norm\n",
            "encoder.block.9.layer.1.dropout\n",
            "encoder.block.10\n",
            "encoder.block.10.layer\n",
            "encoder.block.10.layer.0\n",
            "encoder.block.10.layer.0.SelfAttention\n",
            "encoder.block.10.layer.0.SelfAttention.q\n",
            "encoder.block.10.layer.0.SelfAttention.k\n",
            "encoder.block.10.layer.0.SelfAttention.v\n",
            "encoder.block.10.layer.0.SelfAttention.o\n",
            "encoder.block.10.layer.0.layer_norm\n",
            "encoder.block.10.layer.0.dropout\n",
            "encoder.block.10.layer.1\n",
            "encoder.block.10.layer.1.DenseReluDense\n",
            "encoder.block.10.layer.1.DenseReluDense.wi\n",
            "encoder.block.10.layer.1.DenseReluDense.wo\n",
            "encoder.block.10.layer.1.DenseReluDense.dropout\n",
            "encoder.block.10.layer.1.DenseReluDense.act\n",
            "encoder.block.10.layer.1.layer_norm\n",
            "encoder.block.10.layer.1.dropout\n",
            "encoder.block.11\n",
            "encoder.block.11.layer\n",
            "encoder.block.11.layer.0\n",
            "encoder.block.11.layer.0.SelfAttention\n",
            "encoder.block.11.layer.0.SelfAttention.q\n",
            "encoder.block.11.layer.0.SelfAttention.k\n",
            "encoder.block.11.layer.0.SelfAttention.v\n",
            "encoder.block.11.layer.0.SelfAttention.o\n",
            "encoder.block.11.layer.0.layer_norm\n",
            "encoder.block.11.layer.0.dropout\n",
            "encoder.block.11.layer.1\n",
            "encoder.block.11.layer.1.DenseReluDense\n",
            "encoder.block.11.layer.1.DenseReluDense.wi\n",
            "encoder.block.11.layer.1.DenseReluDense.wo\n",
            "encoder.block.11.layer.1.DenseReluDense.dropout\n",
            "encoder.block.11.layer.1.DenseReluDense.act\n",
            "encoder.block.11.layer.1.layer_norm\n",
            "encoder.block.11.layer.1.dropout\n",
            "encoder.block.12\n",
            "encoder.block.12.layer\n",
            "encoder.block.12.layer.0\n",
            "encoder.block.12.layer.0.SelfAttention\n",
            "encoder.block.12.layer.0.SelfAttention.q\n",
            "encoder.block.12.layer.0.SelfAttention.k\n",
            "encoder.block.12.layer.0.SelfAttention.v\n",
            "encoder.block.12.layer.0.SelfAttention.o\n",
            "encoder.block.12.layer.0.layer_norm\n",
            "encoder.block.12.layer.0.dropout\n",
            "encoder.block.12.layer.1\n",
            "encoder.block.12.layer.1.DenseReluDense\n",
            "encoder.block.12.layer.1.DenseReluDense.wi\n",
            "encoder.block.12.layer.1.DenseReluDense.wo\n",
            "encoder.block.12.layer.1.DenseReluDense.dropout\n",
            "encoder.block.12.layer.1.DenseReluDense.act\n",
            "encoder.block.12.layer.1.layer_norm\n",
            "encoder.block.12.layer.1.dropout\n",
            "encoder.block.13\n",
            "encoder.block.13.layer\n",
            "encoder.block.13.layer.0\n",
            "encoder.block.13.layer.0.SelfAttention\n",
            "encoder.block.13.layer.0.SelfAttention.q\n",
            "encoder.block.13.layer.0.SelfAttention.k\n",
            "encoder.block.13.layer.0.SelfAttention.v\n",
            "encoder.block.13.layer.0.SelfAttention.o\n",
            "encoder.block.13.layer.0.layer_norm\n",
            "encoder.block.13.layer.0.dropout\n",
            "encoder.block.13.layer.1\n",
            "encoder.block.13.layer.1.DenseReluDense\n",
            "encoder.block.13.layer.1.DenseReluDense.wi\n",
            "encoder.block.13.layer.1.DenseReluDense.wo\n",
            "encoder.block.13.layer.1.DenseReluDense.dropout\n",
            "encoder.block.13.layer.1.DenseReluDense.act\n",
            "encoder.block.13.layer.1.layer_norm\n",
            "encoder.block.13.layer.1.dropout\n",
            "encoder.block.14\n",
            "encoder.block.14.layer\n",
            "encoder.block.14.layer.0\n",
            "encoder.block.14.layer.0.SelfAttention\n",
            "encoder.block.14.layer.0.SelfAttention.q\n",
            "encoder.block.14.layer.0.SelfAttention.k\n",
            "encoder.block.14.layer.0.SelfAttention.v\n",
            "encoder.block.14.layer.0.SelfAttention.o\n",
            "encoder.block.14.layer.0.layer_norm\n",
            "encoder.block.14.layer.0.dropout\n",
            "encoder.block.14.layer.1\n",
            "encoder.block.14.layer.1.DenseReluDense\n",
            "encoder.block.14.layer.1.DenseReluDense.wi\n",
            "encoder.block.14.layer.1.DenseReluDense.wo\n",
            "encoder.block.14.layer.1.DenseReluDense.dropout\n",
            "encoder.block.14.layer.1.DenseReluDense.act\n",
            "encoder.block.14.layer.1.layer_norm\n",
            "encoder.block.14.layer.1.dropout\n",
            "encoder.block.15\n",
            "encoder.block.15.layer\n",
            "encoder.block.15.layer.0\n",
            "encoder.block.15.layer.0.SelfAttention\n",
            "encoder.block.15.layer.0.SelfAttention.q\n",
            "encoder.block.15.layer.0.SelfAttention.k\n",
            "encoder.block.15.layer.0.SelfAttention.v\n",
            "encoder.block.15.layer.0.SelfAttention.o\n",
            "encoder.block.15.layer.0.layer_norm\n",
            "encoder.block.15.layer.0.dropout\n",
            "encoder.block.15.layer.1\n",
            "encoder.block.15.layer.1.DenseReluDense\n",
            "encoder.block.15.layer.1.DenseReluDense.wi\n",
            "encoder.block.15.layer.1.DenseReluDense.wo\n",
            "encoder.block.15.layer.1.DenseReluDense.dropout\n",
            "encoder.block.15.layer.1.DenseReluDense.act\n",
            "encoder.block.15.layer.1.layer_norm\n",
            "encoder.block.15.layer.1.dropout\n",
            "encoder.block.16\n",
            "encoder.block.16.layer\n",
            "encoder.block.16.layer.0\n",
            "encoder.block.16.layer.0.SelfAttention\n",
            "encoder.block.16.layer.0.SelfAttention.q\n",
            "encoder.block.16.layer.0.SelfAttention.k\n",
            "encoder.block.16.layer.0.SelfAttention.v\n",
            "encoder.block.16.layer.0.SelfAttention.o\n",
            "encoder.block.16.layer.0.layer_norm\n",
            "encoder.block.16.layer.0.dropout\n",
            "encoder.block.16.layer.1\n",
            "encoder.block.16.layer.1.DenseReluDense\n",
            "encoder.block.16.layer.1.DenseReluDense.wi\n",
            "encoder.block.16.layer.1.DenseReluDense.wo\n",
            "encoder.block.16.layer.1.DenseReluDense.dropout\n",
            "encoder.block.16.layer.1.DenseReluDense.act\n",
            "encoder.block.16.layer.1.layer_norm\n",
            "encoder.block.16.layer.1.dropout\n",
            "encoder.block.17\n",
            "encoder.block.17.layer\n",
            "encoder.block.17.layer.0\n",
            "encoder.block.17.layer.0.SelfAttention\n",
            "encoder.block.17.layer.0.SelfAttention.q\n",
            "encoder.block.17.layer.0.SelfAttention.k\n",
            "encoder.block.17.layer.0.SelfAttention.v\n",
            "encoder.block.17.layer.0.SelfAttention.o\n",
            "encoder.block.17.layer.0.layer_norm\n",
            "encoder.block.17.layer.0.dropout\n",
            "encoder.block.17.layer.1\n",
            "encoder.block.17.layer.1.DenseReluDense\n",
            "encoder.block.17.layer.1.DenseReluDense.wi\n",
            "encoder.block.17.layer.1.DenseReluDense.wo\n",
            "encoder.block.17.layer.1.DenseReluDense.dropout\n",
            "encoder.block.17.layer.1.DenseReluDense.act\n",
            "encoder.block.17.layer.1.layer_norm\n",
            "encoder.block.17.layer.1.dropout\n",
            "encoder.block.18\n",
            "encoder.block.18.layer\n",
            "encoder.block.18.layer.0\n",
            "encoder.block.18.layer.0.SelfAttention\n",
            "encoder.block.18.layer.0.SelfAttention.q\n",
            "encoder.block.18.layer.0.SelfAttention.k\n",
            "encoder.block.18.layer.0.SelfAttention.v\n",
            "encoder.block.18.layer.0.SelfAttention.o\n",
            "encoder.block.18.layer.0.layer_norm\n",
            "encoder.block.18.layer.0.dropout\n",
            "encoder.block.18.layer.1\n",
            "encoder.block.18.layer.1.DenseReluDense\n",
            "encoder.block.18.layer.1.DenseReluDense.wi\n",
            "encoder.block.18.layer.1.DenseReluDense.wo\n",
            "encoder.block.18.layer.1.DenseReluDense.dropout\n",
            "encoder.block.18.layer.1.DenseReluDense.act\n",
            "encoder.block.18.layer.1.layer_norm\n",
            "encoder.block.18.layer.1.dropout\n",
            "encoder.block.19\n",
            "encoder.block.19.layer\n",
            "encoder.block.19.layer.0\n",
            "encoder.block.19.layer.0.SelfAttention\n",
            "encoder.block.19.layer.0.SelfAttention.q\n",
            "encoder.block.19.layer.0.SelfAttention.k\n",
            "encoder.block.19.layer.0.SelfAttention.v\n",
            "encoder.block.19.layer.0.SelfAttention.o\n",
            "encoder.block.19.layer.0.layer_norm\n",
            "encoder.block.19.layer.0.dropout\n",
            "encoder.block.19.layer.1\n",
            "encoder.block.19.layer.1.DenseReluDense\n",
            "encoder.block.19.layer.1.DenseReluDense.wi\n",
            "encoder.block.19.layer.1.DenseReluDense.wo\n",
            "encoder.block.19.layer.1.DenseReluDense.dropout\n",
            "encoder.block.19.layer.1.DenseReluDense.act\n",
            "encoder.block.19.layer.1.layer_norm\n",
            "encoder.block.19.layer.1.dropout\n",
            "encoder.block.20\n",
            "encoder.block.20.layer\n",
            "encoder.block.20.layer.0\n",
            "encoder.block.20.layer.0.SelfAttention\n",
            "encoder.block.20.layer.0.SelfAttention.q\n",
            "encoder.block.20.layer.0.SelfAttention.k\n",
            "encoder.block.20.layer.0.SelfAttention.v\n",
            "encoder.block.20.layer.0.SelfAttention.o\n",
            "encoder.block.20.layer.0.layer_norm\n",
            "encoder.block.20.layer.0.dropout\n",
            "encoder.block.20.layer.1\n",
            "encoder.block.20.layer.1.DenseReluDense\n",
            "encoder.block.20.layer.1.DenseReluDense.wi\n",
            "encoder.block.20.layer.1.DenseReluDense.wo\n",
            "encoder.block.20.layer.1.DenseReluDense.dropout\n",
            "encoder.block.20.layer.1.DenseReluDense.act\n",
            "encoder.block.20.layer.1.layer_norm\n",
            "encoder.block.20.layer.1.dropout\n",
            "encoder.block.21\n",
            "encoder.block.21.layer\n",
            "encoder.block.21.layer.0\n",
            "encoder.block.21.layer.0.SelfAttention\n",
            "encoder.block.21.layer.0.SelfAttention.q\n",
            "encoder.block.21.layer.0.SelfAttention.k\n",
            "encoder.block.21.layer.0.SelfAttention.v\n",
            "encoder.block.21.layer.0.SelfAttention.o\n",
            "encoder.block.21.layer.0.layer_norm\n",
            "encoder.block.21.layer.0.dropout\n",
            "encoder.block.21.layer.1\n",
            "encoder.block.21.layer.1.DenseReluDense\n",
            "encoder.block.21.layer.1.DenseReluDense.wi\n",
            "encoder.block.21.layer.1.DenseReluDense.wo\n",
            "encoder.block.21.layer.1.DenseReluDense.dropout\n",
            "encoder.block.21.layer.1.DenseReluDense.act\n",
            "encoder.block.21.layer.1.layer_norm\n",
            "encoder.block.21.layer.1.dropout\n",
            "encoder.block.22\n",
            "encoder.block.22.layer\n",
            "encoder.block.22.layer.0\n",
            "encoder.block.22.layer.0.SelfAttention\n",
            "encoder.block.22.layer.0.SelfAttention.q\n",
            "encoder.block.22.layer.0.SelfAttention.k\n",
            "encoder.block.22.layer.0.SelfAttention.v\n",
            "encoder.block.22.layer.0.SelfAttention.o\n",
            "encoder.block.22.layer.0.layer_norm\n",
            "encoder.block.22.layer.0.dropout\n",
            "encoder.block.22.layer.1\n",
            "encoder.block.22.layer.1.DenseReluDense\n",
            "encoder.block.22.layer.1.DenseReluDense.wi\n",
            "encoder.block.22.layer.1.DenseReluDense.wo\n",
            "encoder.block.22.layer.1.DenseReluDense.dropout\n",
            "encoder.block.22.layer.1.DenseReluDense.act\n",
            "encoder.block.22.layer.1.layer_norm\n",
            "encoder.block.22.layer.1.dropout\n",
            "encoder.block.23\n",
            "encoder.block.23.layer\n",
            "encoder.block.23.layer.0\n",
            "encoder.block.23.layer.0.SelfAttention\n",
            "encoder.block.23.layer.0.SelfAttention.q\n",
            "encoder.block.23.layer.0.SelfAttention.k\n",
            "encoder.block.23.layer.0.SelfAttention.v\n",
            "encoder.block.23.layer.0.SelfAttention.o\n",
            "encoder.block.23.layer.0.layer_norm\n",
            "encoder.block.23.layer.0.dropout\n",
            "encoder.block.23.layer.1\n",
            "encoder.block.23.layer.1.DenseReluDense\n",
            "encoder.block.23.layer.1.DenseReluDense.wi\n",
            "encoder.block.23.layer.1.DenseReluDense.wo\n",
            "encoder.block.23.layer.1.DenseReluDense.dropout\n",
            "encoder.block.23.layer.1.DenseReluDense.act\n",
            "encoder.block.23.layer.1.layer_norm\n",
            "encoder.block.23.layer.1.dropout\n",
            "encoder.final_layer_norm\n",
            "encoder.dropout\n",
            "decoder\n",
            "decoder.block\n",
            "decoder.block.0\n",
            "decoder.block.0.layer\n",
            "decoder.block.0.layer.0\n",
            "decoder.block.0.layer.0.SelfAttention\n",
            "decoder.block.0.layer.0.SelfAttention.q\n",
            "decoder.block.0.layer.0.SelfAttention.k\n",
            "decoder.block.0.layer.0.SelfAttention.v\n",
            "decoder.block.0.layer.0.SelfAttention.o\n",
            "decoder.block.0.layer.0.SelfAttention.relative_attention_bias\n",
            "decoder.block.0.layer.0.layer_norm\n",
            "decoder.block.0.layer.0.dropout\n",
            "decoder.block.0.layer.1\n",
            "decoder.block.0.layer.1.EncDecAttention\n",
            "decoder.block.0.layer.1.EncDecAttention.q\n",
            "decoder.block.0.layer.1.EncDecAttention.k\n",
            "decoder.block.0.layer.1.EncDecAttention.v\n",
            "decoder.block.0.layer.1.EncDecAttention.o\n",
            "decoder.block.0.layer.1.layer_norm\n",
            "decoder.block.0.layer.1.dropout\n",
            "decoder.block.0.layer.2\n",
            "decoder.block.0.layer.2.DenseReluDense\n",
            "decoder.block.0.layer.2.DenseReluDense.wi\n",
            "decoder.block.0.layer.2.DenseReluDense.wo\n",
            "decoder.block.0.layer.2.DenseReluDense.dropout\n",
            "decoder.block.0.layer.2.DenseReluDense.act\n",
            "decoder.block.0.layer.2.layer_norm\n",
            "decoder.block.0.layer.2.dropout\n",
            "decoder.block.1\n",
            "decoder.block.1.layer\n",
            "decoder.block.1.layer.0\n",
            "decoder.block.1.layer.0.SelfAttention\n",
            "decoder.block.1.layer.0.SelfAttention.q\n",
            "decoder.block.1.layer.0.SelfAttention.k\n",
            "decoder.block.1.layer.0.SelfAttention.v\n",
            "decoder.block.1.layer.0.SelfAttention.o\n",
            "decoder.block.1.layer.0.layer_norm\n",
            "decoder.block.1.layer.0.dropout\n",
            "decoder.block.1.layer.1\n",
            "decoder.block.1.layer.1.EncDecAttention\n",
            "decoder.block.1.layer.1.EncDecAttention.q\n",
            "decoder.block.1.layer.1.EncDecAttention.k\n",
            "decoder.block.1.layer.1.EncDecAttention.v\n",
            "decoder.block.1.layer.1.EncDecAttention.o\n",
            "decoder.block.1.layer.1.layer_norm\n",
            "decoder.block.1.layer.1.dropout\n",
            "decoder.block.1.layer.2\n",
            "decoder.block.1.layer.2.DenseReluDense\n",
            "decoder.block.1.layer.2.DenseReluDense.wi\n",
            "decoder.block.1.layer.2.DenseReluDense.wo\n",
            "decoder.block.1.layer.2.DenseReluDense.dropout\n",
            "decoder.block.1.layer.2.DenseReluDense.act\n",
            "decoder.block.1.layer.2.layer_norm\n",
            "decoder.block.1.layer.2.dropout\n",
            "decoder.block.2\n",
            "decoder.block.2.layer\n",
            "decoder.block.2.layer.0\n",
            "decoder.block.2.layer.0.SelfAttention\n",
            "decoder.block.2.layer.0.SelfAttention.q\n",
            "decoder.block.2.layer.0.SelfAttention.k\n",
            "decoder.block.2.layer.0.SelfAttention.v\n",
            "decoder.block.2.layer.0.SelfAttention.o\n",
            "decoder.block.2.layer.0.layer_norm\n",
            "decoder.block.2.layer.0.dropout\n",
            "decoder.block.2.layer.1\n",
            "decoder.block.2.layer.1.EncDecAttention\n",
            "decoder.block.2.layer.1.EncDecAttention.q\n",
            "decoder.block.2.layer.1.EncDecAttention.k\n",
            "decoder.block.2.layer.1.EncDecAttention.v\n",
            "decoder.block.2.layer.1.EncDecAttention.o\n",
            "decoder.block.2.layer.1.layer_norm\n",
            "decoder.block.2.layer.1.dropout\n",
            "decoder.block.2.layer.2\n",
            "decoder.block.2.layer.2.DenseReluDense\n",
            "decoder.block.2.layer.2.DenseReluDense.wi\n",
            "decoder.block.2.layer.2.DenseReluDense.wo\n",
            "decoder.block.2.layer.2.DenseReluDense.dropout\n",
            "decoder.block.2.layer.2.DenseReluDense.act\n",
            "decoder.block.2.layer.2.layer_norm\n",
            "decoder.block.2.layer.2.dropout\n",
            "decoder.block.3\n",
            "decoder.block.3.layer\n",
            "decoder.block.3.layer.0\n",
            "decoder.block.3.layer.0.SelfAttention\n",
            "decoder.block.3.layer.0.SelfAttention.q\n",
            "decoder.block.3.layer.0.SelfAttention.k\n",
            "decoder.block.3.layer.0.SelfAttention.v\n",
            "decoder.block.3.layer.0.SelfAttention.o\n",
            "decoder.block.3.layer.0.layer_norm\n",
            "decoder.block.3.layer.0.dropout\n",
            "decoder.block.3.layer.1\n",
            "decoder.block.3.layer.1.EncDecAttention\n",
            "decoder.block.3.layer.1.EncDecAttention.q\n",
            "decoder.block.3.layer.1.EncDecAttention.k\n",
            "decoder.block.3.layer.1.EncDecAttention.v\n",
            "decoder.block.3.layer.1.EncDecAttention.o\n",
            "decoder.block.3.layer.1.layer_norm\n",
            "decoder.block.3.layer.1.dropout\n",
            "decoder.block.3.layer.2\n",
            "decoder.block.3.layer.2.DenseReluDense\n",
            "decoder.block.3.layer.2.DenseReluDense.wi\n",
            "decoder.block.3.layer.2.DenseReluDense.wo\n",
            "decoder.block.3.layer.2.DenseReluDense.dropout\n",
            "decoder.block.3.layer.2.DenseReluDense.act\n",
            "decoder.block.3.layer.2.layer_norm\n",
            "decoder.block.3.layer.2.dropout\n",
            "decoder.block.4\n",
            "decoder.block.4.layer\n",
            "decoder.block.4.layer.0\n",
            "decoder.block.4.layer.0.SelfAttention\n",
            "decoder.block.4.layer.0.SelfAttention.q\n",
            "decoder.block.4.layer.0.SelfAttention.k\n",
            "decoder.block.4.layer.0.SelfAttention.v\n",
            "decoder.block.4.layer.0.SelfAttention.o\n",
            "decoder.block.4.layer.0.layer_norm\n",
            "decoder.block.4.layer.0.dropout\n",
            "decoder.block.4.layer.1\n",
            "decoder.block.4.layer.1.EncDecAttention\n",
            "decoder.block.4.layer.1.EncDecAttention.q\n",
            "decoder.block.4.layer.1.EncDecAttention.k\n",
            "decoder.block.4.layer.1.EncDecAttention.v\n",
            "decoder.block.4.layer.1.EncDecAttention.o\n",
            "decoder.block.4.layer.1.layer_norm\n",
            "decoder.block.4.layer.1.dropout\n",
            "decoder.block.4.layer.2\n",
            "decoder.block.4.layer.2.DenseReluDense\n",
            "decoder.block.4.layer.2.DenseReluDense.wi\n",
            "decoder.block.4.layer.2.DenseReluDense.wo\n",
            "decoder.block.4.layer.2.DenseReluDense.dropout\n",
            "decoder.block.4.layer.2.DenseReluDense.act\n",
            "decoder.block.4.layer.2.layer_norm\n",
            "decoder.block.4.layer.2.dropout\n",
            "decoder.block.5\n",
            "decoder.block.5.layer\n",
            "decoder.block.5.layer.0\n",
            "decoder.block.5.layer.0.SelfAttention\n",
            "decoder.block.5.layer.0.SelfAttention.q\n",
            "decoder.block.5.layer.0.SelfAttention.k\n",
            "decoder.block.5.layer.0.SelfAttention.v\n",
            "decoder.block.5.layer.0.SelfAttention.o\n",
            "decoder.block.5.layer.0.layer_norm\n",
            "decoder.block.5.layer.0.dropout\n",
            "decoder.block.5.layer.1\n",
            "decoder.block.5.layer.1.EncDecAttention\n",
            "decoder.block.5.layer.1.EncDecAttention.q\n",
            "decoder.block.5.layer.1.EncDecAttention.k\n",
            "decoder.block.5.layer.1.EncDecAttention.v\n",
            "decoder.block.5.layer.1.EncDecAttention.o\n",
            "decoder.block.5.layer.1.layer_norm\n",
            "decoder.block.5.layer.1.dropout\n",
            "decoder.block.5.layer.2\n",
            "decoder.block.5.layer.2.DenseReluDense\n",
            "decoder.block.5.layer.2.DenseReluDense.wi\n",
            "decoder.block.5.layer.2.DenseReluDense.wo\n",
            "decoder.block.5.layer.2.DenseReluDense.dropout\n",
            "decoder.block.5.layer.2.DenseReluDense.act\n",
            "decoder.block.5.layer.2.layer_norm\n",
            "decoder.block.5.layer.2.dropout\n",
            "decoder.block.6\n",
            "decoder.block.6.layer\n",
            "decoder.block.6.layer.0\n",
            "decoder.block.6.layer.0.SelfAttention\n",
            "decoder.block.6.layer.0.SelfAttention.q\n",
            "decoder.block.6.layer.0.SelfAttention.k\n",
            "decoder.block.6.layer.0.SelfAttention.v\n",
            "decoder.block.6.layer.0.SelfAttention.o\n",
            "decoder.block.6.layer.0.layer_norm\n",
            "decoder.block.6.layer.0.dropout\n",
            "decoder.block.6.layer.1\n",
            "decoder.block.6.layer.1.EncDecAttention\n",
            "decoder.block.6.layer.1.EncDecAttention.q\n",
            "decoder.block.6.layer.1.EncDecAttention.k\n",
            "decoder.block.6.layer.1.EncDecAttention.v\n",
            "decoder.block.6.layer.1.EncDecAttention.o\n",
            "decoder.block.6.layer.1.layer_norm\n",
            "decoder.block.6.layer.1.dropout\n",
            "decoder.block.6.layer.2\n",
            "decoder.block.6.layer.2.DenseReluDense\n",
            "decoder.block.6.layer.2.DenseReluDense.wi\n",
            "decoder.block.6.layer.2.DenseReluDense.wo\n",
            "decoder.block.6.layer.2.DenseReluDense.dropout\n",
            "decoder.block.6.layer.2.DenseReluDense.act\n",
            "decoder.block.6.layer.2.layer_norm\n",
            "decoder.block.6.layer.2.dropout\n",
            "decoder.block.7\n",
            "decoder.block.7.layer\n",
            "decoder.block.7.layer.0\n",
            "decoder.block.7.layer.0.SelfAttention\n",
            "decoder.block.7.layer.0.SelfAttention.q\n",
            "decoder.block.7.layer.0.SelfAttention.k\n",
            "decoder.block.7.layer.0.SelfAttention.v\n",
            "decoder.block.7.layer.0.SelfAttention.o\n",
            "decoder.block.7.layer.0.layer_norm\n",
            "decoder.block.7.layer.0.dropout\n",
            "decoder.block.7.layer.1\n",
            "decoder.block.7.layer.1.EncDecAttention\n",
            "decoder.block.7.layer.1.EncDecAttention.q\n",
            "decoder.block.7.layer.1.EncDecAttention.k\n",
            "decoder.block.7.layer.1.EncDecAttention.v\n",
            "decoder.block.7.layer.1.EncDecAttention.o\n",
            "decoder.block.7.layer.1.layer_norm\n",
            "decoder.block.7.layer.1.dropout\n",
            "decoder.block.7.layer.2\n",
            "decoder.block.7.layer.2.DenseReluDense\n",
            "decoder.block.7.layer.2.DenseReluDense.wi\n",
            "decoder.block.7.layer.2.DenseReluDense.wo\n",
            "decoder.block.7.layer.2.DenseReluDense.dropout\n",
            "decoder.block.7.layer.2.DenseReluDense.act\n",
            "decoder.block.7.layer.2.layer_norm\n",
            "decoder.block.7.layer.2.dropout\n",
            "decoder.block.8\n",
            "decoder.block.8.layer\n",
            "decoder.block.8.layer.0\n",
            "decoder.block.8.layer.0.SelfAttention\n",
            "decoder.block.8.layer.0.SelfAttention.q\n",
            "decoder.block.8.layer.0.SelfAttention.k\n",
            "decoder.block.8.layer.0.SelfAttention.v\n",
            "decoder.block.8.layer.0.SelfAttention.o\n",
            "decoder.block.8.layer.0.layer_norm\n",
            "decoder.block.8.layer.0.dropout\n",
            "decoder.block.8.layer.1\n",
            "decoder.block.8.layer.1.EncDecAttention\n",
            "decoder.block.8.layer.1.EncDecAttention.q\n",
            "decoder.block.8.layer.1.EncDecAttention.k\n",
            "decoder.block.8.layer.1.EncDecAttention.v\n",
            "decoder.block.8.layer.1.EncDecAttention.o\n",
            "decoder.block.8.layer.1.layer_norm\n",
            "decoder.block.8.layer.1.dropout\n",
            "decoder.block.8.layer.2\n",
            "decoder.block.8.layer.2.DenseReluDense\n",
            "decoder.block.8.layer.2.DenseReluDense.wi\n",
            "decoder.block.8.layer.2.DenseReluDense.wo\n",
            "decoder.block.8.layer.2.DenseReluDense.dropout\n",
            "decoder.block.8.layer.2.DenseReluDense.act\n",
            "decoder.block.8.layer.2.layer_norm\n",
            "decoder.block.8.layer.2.dropout\n",
            "decoder.block.9\n",
            "decoder.block.9.layer\n",
            "decoder.block.9.layer.0\n",
            "decoder.block.9.layer.0.SelfAttention\n",
            "decoder.block.9.layer.0.SelfAttention.q\n",
            "decoder.block.9.layer.0.SelfAttention.k\n",
            "decoder.block.9.layer.0.SelfAttention.v\n",
            "decoder.block.9.layer.0.SelfAttention.o\n",
            "decoder.block.9.layer.0.layer_norm\n",
            "decoder.block.9.layer.0.dropout\n",
            "decoder.block.9.layer.1\n",
            "decoder.block.9.layer.1.EncDecAttention\n",
            "decoder.block.9.layer.1.EncDecAttention.q\n",
            "decoder.block.9.layer.1.EncDecAttention.k\n",
            "decoder.block.9.layer.1.EncDecAttention.v\n",
            "decoder.block.9.layer.1.EncDecAttention.o\n",
            "decoder.block.9.layer.1.layer_norm\n",
            "decoder.block.9.layer.1.dropout\n",
            "decoder.block.9.layer.2\n",
            "decoder.block.9.layer.2.DenseReluDense\n",
            "decoder.block.9.layer.2.DenseReluDense.wi\n",
            "decoder.block.9.layer.2.DenseReluDense.wo\n",
            "decoder.block.9.layer.2.DenseReluDense.dropout\n",
            "decoder.block.9.layer.2.DenseReluDense.act\n",
            "decoder.block.9.layer.2.layer_norm\n",
            "decoder.block.9.layer.2.dropout\n",
            "decoder.block.10\n",
            "decoder.block.10.layer\n",
            "decoder.block.10.layer.0\n",
            "decoder.block.10.layer.0.SelfAttention\n",
            "decoder.block.10.layer.0.SelfAttention.q\n",
            "decoder.block.10.layer.0.SelfAttention.k\n",
            "decoder.block.10.layer.0.SelfAttention.v\n",
            "decoder.block.10.layer.0.SelfAttention.o\n",
            "decoder.block.10.layer.0.layer_norm\n",
            "decoder.block.10.layer.0.dropout\n",
            "decoder.block.10.layer.1\n",
            "decoder.block.10.layer.1.EncDecAttention\n",
            "decoder.block.10.layer.1.EncDecAttention.q\n",
            "decoder.block.10.layer.1.EncDecAttention.k\n",
            "decoder.block.10.layer.1.EncDecAttention.v\n",
            "decoder.block.10.layer.1.EncDecAttention.o\n",
            "decoder.block.10.layer.1.layer_norm\n",
            "decoder.block.10.layer.1.dropout\n",
            "decoder.block.10.layer.2\n",
            "decoder.block.10.layer.2.DenseReluDense\n",
            "decoder.block.10.layer.2.DenseReluDense.wi\n",
            "decoder.block.10.layer.2.DenseReluDense.wo\n",
            "decoder.block.10.layer.2.DenseReluDense.dropout\n",
            "decoder.block.10.layer.2.DenseReluDense.act\n",
            "decoder.block.10.layer.2.layer_norm\n",
            "decoder.block.10.layer.2.dropout\n",
            "decoder.block.11\n",
            "decoder.block.11.layer\n",
            "decoder.block.11.layer.0\n",
            "decoder.block.11.layer.0.SelfAttention\n",
            "decoder.block.11.layer.0.SelfAttention.q\n",
            "decoder.block.11.layer.0.SelfAttention.k\n",
            "decoder.block.11.layer.0.SelfAttention.v\n",
            "decoder.block.11.layer.0.SelfAttention.o\n",
            "decoder.block.11.layer.0.layer_norm\n",
            "decoder.block.11.layer.0.dropout\n",
            "decoder.block.11.layer.1\n",
            "decoder.block.11.layer.1.EncDecAttention\n",
            "decoder.block.11.layer.1.EncDecAttention.q\n",
            "decoder.block.11.layer.1.EncDecAttention.k\n",
            "decoder.block.11.layer.1.EncDecAttention.v\n",
            "decoder.block.11.layer.1.EncDecAttention.o\n",
            "decoder.block.11.layer.1.layer_norm\n",
            "decoder.block.11.layer.1.dropout\n",
            "decoder.block.11.layer.2\n",
            "decoder.block.11.layer.2.DenseReluDense\n",
            "decoder.block.11.layer.2.DenseReluDense.wi\n",
            "decoder.block.11.layer.2.DenseReluDense.wo\n",
            "decoder.block.11.layer.2.DenseReluDense.dropout\n",
            "decoder.block.11.layer.2.DenseReluDense.act\n",
            "decoder.block.11.layer.2.layer_norm\n",
            "decoder.block.11.layer.2.dropout\n",
            "decoder.block.12\n",
            "decoder.block.12.layer\n",
            "decoder.block.12.layer.0\n",
            "decoder.block.12.layer.0.SelfAttention\n",
            "decoder.block.12.layer.0.SelfAttention.q\n",
            "decoder.block.12.layer.0.SelfAttention.k\n",
            "decoder.block.12.layer.0.SelfAttention.v\n",
            "decoder.block.12.layer.0.SelfAttention.o\n",
            "decoder.block.12.layer.0.layer_norm\n",
            "decoder.block.12.layer.0.dropout\n",
            "decoder.block.12.layer.1\n",
            "decoder.block.12.layer.1.EncDecAttention\n",
            "decoder.block.12.layer.1.EncDecAttention.q\n",
            "decoder.block.12.layer.1.EncDecAttention.k\n",
            "decoder.block.12.layer.1.EncDecAttention.v\n",
            "decoder.block.12.layer.1.EncDecAttention.o\n",
            "decoder.block.12.layer.1.layer_norm\n",
            "decoder.block.12.layer.1.dropout\n",
            "decoder.block.12.layer.2\n",
            "decoder.block.12.layer.2.DenseReluDense\n",
            "decoder.block.12.layer.2.DenseReluDense.wi\n",
            "decoder.block.12.layer.2.DenseReluDense.wo\n",
            "decoder.block.12.layer.2.DenseReluDense.dropout\n",
            "decoder.block.12.layer.2.DenseReluDense.act\n",
            "decoder.block.12.layer.2.layer_norm\n",
            "decoder.block.12.layer.2.dropout\n",
            "decoder.block.13\n",
            "decoder.block.13.layer\n",
            "decoder.block.13.layer.0\n",
            "decoder.block.13.layer.0.SelfAttention\n",
            "decoder.block.13.layer.0.SelfAttention.q\n",
            "decoder.block.13.layer.0.SelfAttention.k\n",
            "decoder.block.13.layer.0.SelfAttention.v\n",
            "decoder.block.13.layer.0.SelfAttention.o\n",
            "decoder.block.13.layer.0.layer_norm\n",
            "decoder.block.13.layer.0.dropout\n",
            "decoder.block.13.layer.1\n",
            "decoder.block.13.layer.1.EncDecAttention\n",
            "decoder.block.13.layer.1.EncDecAttention.q\n",
            "decoder.block.13.layer.1.EncDecAttention.k\n",
            "decoder.block.13.layer.1.EncDecAttention.v\n",
            "decoder.block.13.layer.1.EncDecAttention.o\n",
            "decoder.block.13.layer.1.layer_norm\n",
            "decoder.block.13.layer.1.dropout\n",
            "decoder.block.13.layer.2\n",
            "decoder.block.13.layer.2.DenseReluDense\n",
            "decoder.block.13.layer.2.DenseReluDense.wi\n",
            "decoder.block.13.layer.2.DenseReluDense.wo\n",
            "decoder.block.13.layer.2.DenseReluDense.dropout\n",
            "decoder.block.13.layer.2.DenseReluDense.act\n",
            "decoder.block.13.layer.2.layer_norm\n",
            "decoder.block.13.layer.2.dropout\n",
            "decoder.block.14\n",
            "decoder.block.14.layer\n",
            "decoder.block.14.layer.0\n",
            "decoder.block.14.layer.0.SelfAttention\n",
            "decoder.block.14.layer.0.SelfAttention.q\n",
            "decoder.block.14.layer.0.SelfAttention.k\n",
            "decoder.block.14.layer.0.SelfAttention.v\n",
            "decoder.block.14.layer.0.SelfAttention.o\n",
            "decoder.block.14.layer.0.layer_norm\n",
            "decoder.block.14.layer.0.dropout\n",
            "decoder.block.14.layer.1\n",
            "decoder.block.14.layer.1.EncDecAttention\n",
            "decoder.block.14.layer.1.EncDecAttention.q\n",
            "decoder.block.14.layer.1.EncDecAttention.k\n",
            "decoder.block.14.layer.1.EncDecAttention.v\n",
            "decoder.block.14.layer.1.EncDecAttention.o\n",
            "decoder.block.14.layer.1.layer_norm\n",
            "decoder.block.14.layer.1.dropout\n",
            "decoder.block.14.layer.2\n",
            "decoder.block.14.layer.2.DenseReluDense\n",
            "decoder.block.14.layer.2.DenseReluDense.wi\n",
            "decoder.block.14.layer.2.DenseReluDense.wo\n",
            "decoder.block.14.layer.2.DenseReluDense.dropout\n",
            "decoder.block.14.layer.2.DenseReluDense.act\n",
            "decoder.block.14.layer.2.layer_norm\n",
            "decoder.block.14.layer.2.dropout\n",
            "decoder.block.15\n",
            "decoder.block.15.layer\n",
            "decoder.block.15.layer.0\n",
            "decoder.block.15.layer.0.SelfAttention\n",
            "decoder.block.15.layer.0.SelfAttention.q\n",
            "decoder.block.15.layer.0.SelfAttention.k\n",
            "decoder.block.15.layer.0.SelfAttention.v\n",
            "decoder.block.15.layer.0.SelfAttention.o\n",
            "decoder.block.15.layer.0.layer_norm\n",
            "decoder.block.15.layer.0.dropout\n",
            "decoder.block.15.layer.1\n",
            "decoder.block.15.layer.1.EncDecAttention\n",
            "decoder.block.15.layer.1.EncDecAttention.q\n",
            "decoder.block.15.layer.1.EncDecAttention.k\n",
            "decoder.block.15.layer.1.EncDecAttention.v\n",
            "decoder.block.15.layer.1.EncDecAttention.o\n",
            "decoder.block.15.layer.1.layer_norm\n",
            "decoder.block.15.layer.1.dropout\n",
            "decoder.block.15.layer.2\n",
            "decoder.block.15.layer.2.DenseReluDense\n",
            "decoder.block.15.layer.2.DenseReluDense.wi\n",
            "decoder.block.15.layer.2.DenseReluDense.wo\n",
            "decoder.block.15.layer.2.DenseReluDense.dropout\n",
            "decoder.block.15.layer.2.DenseReluDense.act\n",
            "decoder.block.15.layer.2.layer_norm\n",
            "decoder.block.15.layer.2.dropout\n",
            "decoder.block.16\n",
            "decoder.block.16.layer\n",
            "decoder.block.16.layer.0\n",
            "decoder.block.16.layer.0.SelfAttention\n",
            "decoder.block.16.layer.0.SelfAttention.q\n",
            "decoder.block.16.layer.0.SelfAttention.k\n",
            "decoder.block.16.layer.0.SelfAttention.v\n",
            "decoder.block.16.layer.0.SelfAttention.o\n",
            "decoder.block.16.layer.0.layer_norm\n",
            "decoder.block.16.layer.0.dropout\n",
            "decoder.block.16.layer.1\n",
            "decoder.block.16.layer.1.EncDecAttention\n",
            "decoder.block.16.layer.1.EncDecAttention.q\n",
            "decoder.block.16.layer.1.EncDecAttention.k\n",
            "decoder.block.16.layer.1.EncDecAttention.v\n",
            "decoder.block.16.layer.1.EncDecAttention.o\n",
            "decoder.block.16.layer.1.layer_norm\n",
            "decoder.block.16.layer.1.dropout\n",
            "decoder.block.16.layer.2\n",
            "decoder.block.16.layer.2.DenseReluDense\n",
            "decoder.block.16.layer.2.DenseReluDense.wi\n",
            "decoder.block.16.layer.2.DenseReluDense.wo\n",
            "decoder.block.16.layer.2.DenseReluDense.dropout\n",
            "decoder.block.16.layer.2.DenseReluDense.act\n",
            "decoder.block.16.layer.2.layer_norm\n",
            "decoder.block.16.layer.2.dropout\n",
            "decoder.block.17\n",
            "decoder.block.17.layer\n",
            "decoder.block.17.layer.0\n",
            "decoder.block.17.layer.0.SelfAttention\n",
            "decoder.block.17.layer.0.SelfAttention.q\n",
            "decoder.block.17.layer.0.SelfAttention.k\n",
            "decoder.block.17.layer.0.SelfAttention.v\n",
            "decoder.block.17.layer.0.SelfAttention.o\n",
            "decoder.block.17.layer.0.layer_norm\n",
            "decoder.block.17.layer.0.dropout\n",
            "decoder.block.17.layer.1\n",
            "decoder.block.17.layer.1.EncDecAttention\n",
            "decoder.block.17.layer.1.EncDecAttention.q\n",
            "decoder.block.17.layer.1.EncDecAttention.k\n",
            "decoder.block.17.layer.1.EncDecAttention.v\n",
            "decoder.block.17.layer.1.EncDecAttention.o\n",
            "decoder.block.17.layer.1.layer_norm\n",
            "decoder.block.17.layer.1.dropout\n",
            "decoder.block.17.layer.2\n",
            "decoder.block.17.layer.2.DenseReluDense\n",
            "decoder.block.17.layer.2.DenseReluDense.wi\n",
            "decoder.block.17.layer.2.DenseReluDense.wo\n",
            "decoder.block.17.layer.2.DenseReluDense.dropout\n",
            "decoder.block.17.layer.2.DenseReluDense.act\n",
            "decoder.block.17.layer.2.layer_norm\n",
            "decoder.block.17.layer.2.dropout\n",
            "decoder.block.18\n",
            "decoder.block.18.layer\n",
            "decoder.block.18.layer.0\n",
            "decoder.block.18.layer.0.SelfAttention\n",
            "decoder.block.18.layer.0.SelfAttention.q\n",
            "decoder.block.18.layer.0.SelfAttention.k\n",
            "decoder.block.18.layer.0.SelfAttention.v\n",
            "decoder.block.18.layer.0.SelfAttention.o\n",
            "decoder.block.18.layer.0.layer_norm\n",
            "decoder.block.18.layer.0.dropout\n",
            "decoder.block.18.layer.1\n",
            "decoder.block.18.layer.1.EncDecAttention\n",
            "decoder.block.18.layer.1.EncDecAttention.q\n",
            "decoder.block.18.layer.1.EncDecAttention.k\n",
            "decoder.block.18.layer.1.EncDecAttention.v\n",
            "decoder.block.18.layer.1.EncDecAttention.o\n",
            "decoder.block.18.layer.1.layer_norm\n",
            "decoder.block.18.layer.1.dropout\n",
            "decoder.block.18.layer.2\n",
            "decoder.block.18.layer.2.DenseReluDense\n",
            "decoder.block.18.layer.2.DenseReluDense.wi\n",
            "decoder.block.18.layer.2.DenseReluDense.wo\n",
            "decoder.block.18.layer.2.DenseReluDense.dropout\n",
            "decoder.block.18.layer.2.DenseReluDense.act\n",
            "decoder.block.18.layer.2.layer_norm\n",
            "decoder.block.18.layer.2.dropout\n",
            "decoder.block.19\n",
            "decoder.block.19.layer\n",
            "decoder.block.19.layer.0\n",
            "decoder.block.19.layer.0.SelfAttention\n",
            "decoder.block.19.layer.0.SelfAttention.q\n",
            "decoder.block.19.layer.0.SelfAttention.k\n",
            "decoder.block.19.layer.0.SelfAttention.v\n",
            "decoder.block.19.layer.0.SelfAttention.o\n",
            "decoder.block.19.layer.0.layer_norm\n",
            "decoder.block.19.layer.0.dropout\n",
            "decoder.block.19.layer.1\n",
            "decoder.block.19.layer.1.EncDecAttention\n",
            "decoder.block.19.layer.1.EncDecAttention.q\n",
            "decoder.block.19.layer.1.EncDecAttention.k\n",
            "decoder.block.19.layer.1.EncDecAttention.v\n",
            "decoder.block.19.layer.1.EncDecAttention.o\n",
            "decoder.block.19.layer.1.layer_norm\n",
            "decoder.block.19.layer.1.dropout\n",
            "decoder.block.19.layer.2\n",
            "decoder.block.19.layer.2.DenseReluDense\n",
            "decoder.block.19.layer.2.DenseReluDense.wi\n",
            "decoder.block.19.layer.2.DenseReluDense.wo\n",
            "decoder.block.19.layer.2.DenseReluDense.dropout\n",
            "decoder.block.19.layer.2.DenseReluDense.act\n",
            "decoder.block.19.layer.2.layer_norm\n",
            "decoder.block.19.layer.2.dropout\n",
            "decoder.block.20\n",
            "decoder.block.20.layer\n",
            "decoder.block.20.layer.0\n",
            "decoder.block.20.layer.0.SelfAttention\n",
            "decoder.block.20.layer.0.SelfAttention.q\n",
            "decoder.block.20.layer.0.SelfAttention.k\n",
            "decoder.block.20.layer.0.SelfAttention.v\n",
            "decoder.block.20.layer.0.SelfAttention.o\n",
            "decoder.block.20.layer.0.layer_norm\n",
            "decoder.block.20.layer.0.dropout\n",
            "decoder.block.20.layer.1\n",
            "decoder.block.20.layer.1.EncDecAttention\n",
            "decoder.block.20.layer.1.EncDecAttention.q\n",
            "decoder.block.20.layer.1.EncDecAttention.k\n",
            "decoder.block.20.layer.1.EncDecAttention.v\n",
            "decoder.block.20.layer.1.EncDecAttention.o\n",
            "decoder.block.20.layer.1.layer_norm\n",
            "decoder.block.20.layer.1.dropout\n",
            "decoder.block.20.layer.2\n",
            "decoder.block.20.layer.2.DenseReluDense\n",
            "decoder.block.20.layer.2.DenseReluDense.wi\n",
            "decoder.block.20.layer.2.DenseReluDense.wo\n",
            "decoder.block.20.layer.2.DenseReluDense.dropout\n",
            "decoder.block.20.layer.2.DenseReluDense.act\n",
            "decoder.block.20.layer.2.layer_norm\n",
            "decoder.block.20.layer.2.dropout\n",
            "decoder.block.21\n",
            "decoder.block.21.layer\n",
            "decoder.block.21.layer.0\n",
            "decoder.block.21.layer.0.SelfAttention\n",
            "decoder.block.21.layer.0.SelfAttention.q\n",
            "decoder.block.21.layer.0.SelfAttention.k\n",
            "decoder.block.21.layer.0.SelfAttention.v\n",
            "decoder.block.21.layer.0.SelfAttention.o\n",
            "decoder.block.21.layer.0.layer_norm\n",
            "decoder.block.21.layer.0.dropout\n",
            "decoder.block.21.layer.1\n",
            "decoder.block.21.layer.1.EncDecAttention\n",
            "decoder.block.21.layer.1.EncDecAttention.q\n",
            "decoder.block.21.layer.1.EncDecAttention.k\n",
            "decoder.block.21.layer.1.EncDecAttention.v\n",
            "decoder.block.21.layer.1.EncDecAttention.o\n",
            "decoder.block.21.layer.1.layer_norm\n",
            "decoder.block.21.layer.1.dropout\n",
            "decoder.block.21.layer.2\n",
            "decoder.block.21.layer.2.DenseReluDense\n",
            "decoder.block.21.layer.2.DenseReluDense.wi\n",
            "decoder.block.21.layer.2.DenseReluDense.wo\n",
            "decoder.block.21.layer.2.DenseReluDense.dropout\n",
            "decoder.block.21.layer.2.DenseReluDense.act\n",
            "decoder.block.21.layer.2.layer_norm\n",
            "decoder.block.21.layer.2.dropout\n",
            "decoder.block.22\n",
            "decoder.block.22.layer\n",
            "decoder.block.22.layer.0\n",
            "decoder.block.22.layer.0.SelfAttention\n",
            "decoder.block.22.layer.0.SelfAttention.q\n",
            "decoder.block.22.layer.0.SelfAttention.k\n",
            "decoder.block.22.layer.0.SelfAttention.v\n",
            "decoder.block.22.layer.0.SelfAttention.o\n",
            "decoder.block.22.layer.0.layer_norm\n",
            "decoder.block.22.layer.0.dropout\n",
            "decoder.block.22.layer.1\n",
            "decoder.block.22.layer.1.EncDecAttention\n",
            "decoder.block.22.layer.1.EncDecAttention.q\n",
            "decoder.block.22.layer.1.EncDecAttention.k\n",
            "decoder.block.22.layer.1.EncDecAttention.v\n",
            "decoder.block.22.layer.1.EncDecAttention.o\n",
            "decoder.block.22.layer.1.layer_norm\n",
            "decoder.block.22.layer.1.dropout\n",
            "decoder.block.22.layer.2\n",
            "decoder.block.22.layer.2.DenseReluDense\n",
            "decoder.block.22.layer.2.DenseReluDense.wi\n",
            "decoder.block.22.layer.2.DenseReluDense.wo\n",
            "decoder.block.22.layer.2.DenseReluDense.dropout\n",
            "decoder.block.22.layer.2.DenseReluDense.act\n",
            "decoder.block.22.layer.2.layer_norm\n",
            "decoder.block.22.layer.2.dropout\n",
            "decoder.block.23\n",
            "decoder.block.23.layer\n",
            "decoder.block.23.layer.0\n",
            "decoder.block.23.layer.0.SelfAttention\n",
            "decoder.block.23.layer.0.SelfAttention.q\n",
            "decoder.block.23.layer.0.SelfAttention.k\n",
            "decoder.block.23.layer.0.SelfAttention.v\n",
            "decoder.block.23.layer.0.SelfAttention.o\n",
            "decoder.block.23.layer.0.layer_norm\n",
            "decoder.block.23.layer.0.dropout\n",
            "decoder.block.23.layer.1\n",
            "decoder.block.23.layer.1.EncDecAttention\n",
            "decoder.block.23.layer.1.EncDecAttention.q\n",
            "decoder.block.23.layer.1.EncDecAttention.k\n",
            "decoder.block.23.layer.1.EncDecAttention.v\n",
            "decoder.block.23.layer.1.EncDecAttention.o\n",
            "decoder.block.23.layer.1.layer_norm\n",
            "decoder.block.23.layer.1.dropout\n",
            "decoder.block.23.layer.2\n",
            "decoder.block.23.layer.2.DenseReluDense\n",
            "decoder.block.23.layer.2.DenseReluDense.wi\n",
            "decoder.block.23.layer.2.DenseReluDense.wo\n",
            "decoder.block.23.layer.2.DenseReluDense.dropout\n",
            "decoder.block.23.layer.2.DenseReluDense.act\n",
            "decoder.block.23.layer.2.layer_norm\n",
            "decoder.block.23.layer.2.dropout\n",
            "decoder.final_layer_norm\n",
            "decoder.dropout\n",
            "lm_head\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0TL6_AhSRaq0"
      },
      "outputs": [],
      "source": [
        "i@torch.no_grad()\n",
        "def evaluate(model, messages, testing_dataset, batch_size=16):\n",
        "    \"\"\"\n",
        "    Evaluate the model's performance on the testing dataset.\n",
        "\n",
        "    Args:\n",
        "        model: The pre-trained language model.\n",
        "        messages: The prompt template in the OpenAI message format.\n",
        "        testing_dataset: The dataset containing Q&A pairs for testing.\n",
        "        batch_size: The number of examples to process in a batch.\n",
        "\n",
        "    Returns:\n",
        "        float: Accuracy of the model on the testing dataset.\n",
        "    \"\"\"\n",
        "    num_correct = 0\n",
        "\n",
        "    # Extract the questions and answers as lists\n",
        "    questions = testing_dataset['Question'].tolist()\n",
        "    answers = testing_dataset['Answer'].tolist()\n",
        "\n",
        "    # Create batches manually, since DataLoader is not suitable for non-numeric data\n",
        "    for i in tqdm(range(0, len(questions), batch_size)):\n",
        "        batch_questions = questions[i:i + batch_size]\n",
        "        batch_answers = answers[i:i + batch_size]\n",
        "\n",
        "        # Generate responses in batch\n",
        "        batch_inputs = []\n",
        "        for question in batch_questions:\n",
        "            populated_messages = copy.deepcopy(messages)\n",
        "            for msg in populated_messages:\n",
        "                msg[\"content\"] = msg[\"content\"].replace(\"{SOURCE}\", question)\n",
        "\n",
        "            prompt_text = \" \".join([msg[\"content\"] for msg in populated_messages])\n",
        "            batch_inputs.append(prompt_text)\n",
        "\n",
        "        # Tokenize the batch input\n",
        "        inputs = tokenizer(batch_inputs, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
        "\n",
        "        # Generate outputs in batch\n",
        "        outputs = model.generate(inputs[\"input_ids\"], max_new_tokens=20, do_sample=False)\n",
        "\n",
        "        # Decode outputs and check accuracy\n",
        "        for output_text, answer in zip(outputs, batch_answers):\n",
        "            output_text = tokenizer.decode(output_text, skip_special_tokens=True)\n",
        "            if output_text.strip().lower() == answer.strip().lower():\n",
        "                num_correct += 1\n",
        "\n",
        "    # Calculate and print the accuracy\n",
        "    accuracy = num_correct / len(testing_dataset)\n",
        "    print(f\"ACCURACY = {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sgdJOlEWPP28"
      },
      "outputs": [],
      "source": [
        "# Define a simple baseline prompt\n",
        "my_prompt = [{\"role\": \"user\", \"content\": \"Please generate an answer: {SOURCE}\"}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "ea059d87a7d744528b8c028c8051ec0b",
            "7b61ee67592d4298a9c5dbd3ef5f6875",
            "23394c9f675d4463bfc03e16fa7b1128",
            "5e81d2ecedb149e4809374e1889eab8a",
            "d9be35c8756441b9ac360161b2e618b8",
            "0a8d7767302c4935b00833ceb70e77e0",
            "dc2aa52ad5364afcbb5ebba1e8bad55c",
            "e4098c58cbce45799c77f651d4c892d7",
            "c8a104bc894541e789bd174d02e28819",
            "9e43870a697145efa3188d4565726c69",
            "d5d84a6597a9461abdfb645e88146fc0"
          ]
        },
        "id": "dW-7kjg7hnFb",
        "outputId": "9be7de41-f401-433d-8e9c-efb41b6542fb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea059d87a7d744528b8c028c8051ec0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY = 0.0000\n"
          ]
        }
      ],
      "source": [
        "# Evaluate baseline performance\n",
        "evaluate(model, my_prompt, testing_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.1 Troubleshoot: Model Capability\n",
        "\n",
        "Obtaining ACCURACY = 0.0000, I have switched 3 models to compare their performance and efficiency in this Q&A task.\n",
        "\n",
        "1. The model used (Qwen/Qwen2-0.5B-Instruct, 0.5 billion parameters) may not be sufficiently fine-tuned or powerful enough to handle the specific Q&A pairs in the testing dataset.\n",
        "\n",
        "2. T5-large is a versatile model that has shown strong performance across various NLP tasks, including Q&A. However, this large model (770 million parameters)takes a long time to train.\n",
        "\n",
        "3. T5-small is a smaller version of the T5-large model with 60 million parameters. It can offer efficiency."
      ],
      "metadata": {
        "id": "50LhNwFkxhuX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "55c5d22e595d432cb2f8b3234df5bd01",
            "6f73e6937bc3406cb395091b6afbc74d",
            "48032b38279448f6a99477e24791b139",
            "aa90b5291b4e4cfca7120c90b0b5f631",
            "2ab7836c1e024a73b009468696c707f0",
            "67edad20c98143aaa7f00b551413a6d8",
            "d6212a17531e4eeb85ee178956c58d2d",
            "d24a3447c2a64a90932762cc4ffc2452",
            "d337ec13ab4b4356af8e99b59a7c67da",
            "007b48275b0f4a77a71e183b1fe7aaa8",
            "4fd933dee71c4f00964ec8b869439341",
            "9e898a10d7b84a4fb0007823d16a1fb7",
            "6cd15d64cb874dcab23182ab110e661f",
            "a782464d50894873bac3f80da6bbcaa8",
            "1645116cf4724d08b0a14c11274892f9",
            "6b23ee290e6d45ab8cbf85a16336dab4",
            "0f5f757a294546bfbd52657d8730d209",
            "ebbb4148fefb46bf805d8ca0cb93bb7a",
            "9edda139a7c94ccd9c902fb07c9cce8f",
            "794de245e7834191b1aec0d8d331e5f4",
            "546aba40645c4d859ba8055d040581ef",
            "4d59afcb590b4b8a96f3610c741573a1",
            "7174d0264c4649c29e234231bdba4cba",
            "5b8ccfbd63d54179b15b82812e8b82de",
            "7c715000e5d040b59fceec0df000ca2d",
            "54c5d8115cec42af85539eb543672b4b",
            "1a03bc52654745308f2cefbe253a8118",
            "ebe3de577ab7456ea8eff100dc4309bf",
            "a98cda6f915547af8a2ac8b5482bd43d",
            "0d30b88648f2496db621d47e28211764",
            "ad2f92ad8e854acc99e50e249fce50a4",
            "1af33672b37c403b8b8d9e13ffa36969",
            "1fea98175981449caf5060fa7a05536a",
            "a5b8774aa38f4f78b394bc6151f323fd",
            "8f8ae87c486f440287cea7a3edade9ab",
            "fedfaf60bb914070847d5c8fe56c76e2",
            "66259998c63a46bea51ae3ef18dadc43",
            "c8850a827993408d99b7087809b1fadd",
            "11c9a02f6f374ab59e8a3d5483851333",
            "5ac5851d002740a4948c177868010bc0",
            "bc1a51f1b3b4490dabd79f328d06c2a6",
            "a70aefef4dba4035815c96d60109c9d2",
            "ef700574df334882a71ed2d8fe05c5d8",
            "13e0a1b1b2734e578c699ab6ccfafbb2",
            "e06c7a55948f47db88365d7b42dddd2f",
            "1494d897293e48008b7ce4014a198520",
            "41a987492c6140ebab4a86d9df56c789",
            "d9917034849940d6813813d30f495d84",
            "1bdd22badc4345debf2ebddfc847eddd",
            "0675a1af46f545c7a6196736f010f9e8",
            "8750d466fa5c464b88e5f82e096fc92a",
            "172edb1d55834ac08d2158db31298966",
            "803885c5984f4b05a71bf17ba577706e",
            "2dbb811de37b4fa0aa88e248d6191d31",
            "8e1f4b21a6a1474c94ede4483a2e3aac",
            "2c15df9ee7b146e082d2d756eb0ac8e9",
            "5680503786e04514911b085a74410ce8",
            "85cf719ce7be40b89564a1022504c260",
            "de02da7efaab425788a2c41662eb7de4",
            "09ca5e1c9aa64ab5b67429819aed5b9b",
            "876966c998564bf08422dbdbe2adc85f",
            "43b018835dfa483a8141baf9c55108ea",
            "4d355742c2de49f6aa030497125aefe8",
            "52854316e2674f33a8c69e1d9a517b14",
            "7bccc139beb346a68198033b6d51d00c",
            "b2d2c8c1692c4a9fafea1a46c1948c74"
          ]
        },
        "id": "KUvyhilchTNH",
        "outputId": "86eca453-138e-4f74-a8c8-f967707aacf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55c5d22e595d432cb2f8b3234df5bd01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e898a10d7b84a4fb0007823d16a1fb7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7174d0264c4649c29e234231bdba4cba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5b8774aa38f4f78b394bc6151f323fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e06c7a55948f47db88365d7b42dddd2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c15df9ee7b146e082d2d756eb0ac8e9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load the model and tokenizer\n",
        "# model_name = \"t5-large\"  # Change to a more powerful model\n",
        "model_name = \"t5-small\"  # Change to a smaller model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=\"auto\", device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkLEfXZtWGvA"
      },
      "source": [
        "# 4.2 Troubleshoot: Parameter-Efficient Fine-Tuning\n",
        "\n",
        "We initialize the Parameter-Efficient Fine-Tuning (PEFT) model, which incorporates LoRA. This model will be used to adapt the pre-trained model with fewer parameters, making the fine-tuning process more efficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWcnTucsRaxG",
        "outputId": "7ead1b7e-4f27-43f4-aa2e-57bfacf89a15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.12.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install peft --no-deps"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, TaskType, get_peft_model\n",
        "from pprint import pp\n",
        "from transformers import TrainingArguments, Trainer"
      ],
      "metadata": {
        "id": "Uip-fxsJ2j72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMFf82ErRan8",
        "outputId": "64fe8834-2645-49e6-cc2f-8e4b0b9a2e30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>,\n",
            "           auto_mapping=None,\n",
            "           base_model_name_or_path=None,\n",
            "           revision=None,\n",
            "           task_type=<TaskType.SEQ_2_SEQ_LM: 'SEQ_2_SEQ_LM'>,\n",
            "           inference_mode=False,\n",
            "           r=16,\n",
            "           target_modules={'k', 'q', 'v', 'o'},\n",
            "           lora_alpha=8,\n",
            "           lora_dropout=0.0,\n",
            "           fan_in_fan_out=False,\n",
            "           bias='none',\n",
            "           use_rslora=True,\n",
            "           modules_to_save=None,\n",
            "           init_lora_weights='gaussian',\n",
            "           layers_to_transform=None,\n",
            "           layers_pattern=None,\n",
            "           rank_pattern={},\n",
            "           alpha_pattern={},\n",
            "           megatron_config=None,\n",
            "           megatron_core='megatron.core',\n",
            "           loftq_config={},\n",
            "           use_dora=False,\n",
            "           layer_replication=None,\n",
            "           runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))\n",
            "\n",
            "\n",
            "trainable params: 1,179,648 || all params: 61,686,272 || trainable%: 1.9123\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForSeq2SeqLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): T5ForConditionalGeneration(\n",
              "      (shared): Embedding(32128, 512)\n",
              "      (encoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32128, 512)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (k): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (o): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (relative_attention_bias): Embedding(32, 8)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1-5): 5 x T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (k): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (o): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (decoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32128, 512)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (k): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (o): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (relative_attention_bias): Embedding(32, 8)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (k): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (o): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1-5): 5 x T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (k): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (o): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (k): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (o): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Identity()\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Define PEFT adapter configuration\n",
        "# adapter_config = LoraConfig(init_lora_weights=\"gaussian\", r=16, use_rslora=True, task_type=TaskType.CAUSAL_LM, target_modules=[\"qkv_proj\", \"o_proj\", \"gate_up_proj\", \"down_proj\"])\n",
        "adapter_config = LoraConfig(\n",
        "    init_lora_weights=\"gaussian\",\n",
        "    r=16,\n",
        "    use_rslora=True,\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM,  # Updated TaskType\n",
        "    target_modules=[\"q\", \"k\", \"v\", \"o\"],  # Targeting projection layers\n",
        ")\n",
        "\n",
        "pp(adapter_config)\n",
        "\n",
        "print()\n",
        "print()\n",
        "\n",
        "lora_model = get_peft_model(model, adapter_config)\n",
        "lora_model.print_trainable_parameters()\n",
        "\n",
        "print()\n",
        "print()\n",
        "\n",
        "lora_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G8M9ak8FRak1"
      },
      "outputs": [],
      "source": [
        "# Define the prepare function\n",
        "def prepare(data, messages, tokenizer):\n",
        "    \"\"\"\n",
        "    Prepares the dataset for training by populating message templates with data,\n",
        "    tokenizing the text, and creating input tensors.\n",
        "\n",
        "    Args:\n",
        "    - data: DataFrame containing 'Question' and 'Answer' columns.\n",
        "    - messages: List of message templates to be populated with data.\n",
        "    - tokenizer: Tokenizer for tokenizing the text.\n",
        "\n",
        "    Returns:\n",
        "    - output_dataset: List of dictionaries containing tokenized inputs and attention masks.\n",
        "    \"\"\"\n",
        "    output_dataset = []  # Initialize an empty list to store the prepared data\n",
        "\n",
        "    # Iterate through each row in the DataFrame\n",
        "    for _, row in data.iterrows():\n",
        "        question = row[\"Question\"]  # Extract the question\n",
        "        answer = row[\"Answer\"]  # Extract the answer\n",
        "\n",
        "        # Deep copy the message templates to avoid modifying the original\n",
        "        populated = copy.deepcopy(messages)\n",
        "\n",
        "        # Populate the message template with the question\n",
        "        for msg in populated:\n",
        "            msg[\"content\"] = msg[\"content\"].replace(\"{SOURCE}\", question)\n",
        "\n",
        "        # Append the answer as the assistant's response to the populated messages\n",
        "        populated.append({\"role\": \"assistant\", \"content\": answer})\n",
        "\n",
        "        # Convert populated messages into a single string for tokenization\n",
        "        prepared_instance = \" \".join([msg[\"content\"] for msg in populated])\n",
        "\n",
        "        # Tokenize the prepared instance with padding and truncation\n",
        "        tokenized_instance = tokenizer(prepared_instance, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "        # Append the tokenized inputs and attention mask to the output dataset\n",
        "        output_dataset.append({\n",
        "            \"input_ids\": tokenized_instance[\"input_ids\"][0],\n",
        "            \"attention_mask\": tokenized_instance[\"attention_mask\"][0],\n",
        "            \"labels\": tokenized_instance[\"input_ids\"][0].clone()  # Clone the input_ids to use as labels\n",
        "        })\n",
        "\n",
        "    return output_dataset  # Return the prepared dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w9YUKIPRahe",
        "outputId": "ccfec74c-f723-4696-eaaf-528f8fc378ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please generate an answer: What kind of health-related data does TRUST provide access to? TRUST provides access to a wide range of health-related data, including genomic, behavioural, socio-economic, and clinical data, which covers various aspects such as patient demographics, healthcare utilisation, disease incidence, as well as data on healthcare policy, social determinants of health, and health systems. With this diverse and comprehensive data, researchers can discover new insights that can improve our understanding of health and disease, and ultimately contribute to innovations and breakthroughs in healthcare.</s>\n"
          ]
        }
      ],
      "source": [
        "# Example usage of the prepare function\n",
        "training_dataset = prepare(train_df, my_prompt, tokenizer)\n",
        "\n",
        "# Verify the tokenization by decoding the first set of input_ids\n",
        "print(tokenizer.decode(training_dataset[0][\"input_ids\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "ffbAQzmuRaZX",
        "outputId": "659d54c1-fe24-409b-a4a5-df84462a3311"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='82' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 82/100 3:46:11 < 50:53, 0.01 it/s, Epoch 0.81/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.264100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>3.102800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.886400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.027600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 4:39:46, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.264100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>3.102800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.886400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.027600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.584400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=100, training_loss=2.5730232048034667, metrics={'train_runtime': 16978.1922, 'train_samples_per_second': 0.024, 'train_steps_per_second': 0.006, 'total_flos': 14975451955200.0, 'train_loss': 2.5730232048034667, 'epoch': 1.0025062656641603})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    learning_rate=5e-5,\n",
        "    warmup_steps=50,\n",
        "    weight_decay=0.1,\n",
        "    max_steps=100, # Reduce from 500 to 100\n",
        "    per_device_train_batch_size=1,\n",
        "    logging_steps=20,\n",
        "    do_eval=False,\n",
        "    bf16=True,\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    args=training_args,\n",
        "    train_dataset=training_dataset,\n",
        ")\n",
        "\n",
        "# Fine-tune the model with PEFT\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "1. output_dir: Directory where the model's checkpoints and logs will be saved.\n",
        "2. learning_rate: The initial learning rate for the optimizer, which determines the step size at each iteration while moving toward a minimum of the loss function\n",
        "3. warmup_steps: Number of steps for the warmup phase, where the learning rate gradually increases from 0 to the initial learning rate. This helps stabilize training.\n",
        "4. weight_decay: Regularization technique that reduces the magnitude of the weights, helping to prevent overfitting by penalizing large weights.\n",
        "5. max_steps: Total number of training steps to perform. Reducing this will shorten the training time.\n",
        "6. per_device_train_batch_size: Number of training samples processed simultaneously on each device (e.g., GPU). Larger batch sizes can reduce noise in gradient updates but require more memory.\n",
        "7. logging_steps: Frequency of logging training metrics. It logs after every specified number of steps.\n",
        "8. do_eval: Whether to run evaluation during training. Setting this to False skips the evaluation step, saving time.\n",
        "9. bf16: Use Brain Floating Point 16 (bf16) precision, which speeds up training while preserving more numerical accuracy compared to fp16. Suitable for newer GPUs like NVIDIA A100.\n",
        "\n"
      ],
      "metadata": {
        "id": "TYQBcxaYnlzk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-5jAW0TrRaPS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329,
          "referenced_widgets": [
            "f5eb376b45d840ad88bf70a62153d10d",
            "dba1afe4d8274b18afeb44e5e118753b",
            "7f4d13b359cb4fe8bd6535d63e44631f",
            "3f9216bd6e8e4cddbb9135a42dca1bb4",
            "5ab8e4ed5c6f415b8150124d25525e9d",
            "e45044babb534634b81841ad24b8111d",
            "82ecb7ac898443f78a6de8fb10fc97bc",
            "2178291276f044bdbf0356672f5f2e90",
            "d026236eecdd40c88210743925c8728b",
            "485ec8fc10f64cf684bf65545722ee8f",
            "cf0772c8aabe44888afd2132451a97d9"
          ]
        },
        "outputId": "79c43d80-6c53-4ae0-c5de-bed3d7cd7cc4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5eb376b45d840ad88bf70a62153d10d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:562: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY = 0.0000\n"
          ]
        }
      ],
      "source": [
        "evaluate(lora_model, my_prompt, testing_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DFWrntdQQslV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "2c14ab21ac454a20915a8582d6c1d3ff",
            "a5eaecfff2084b86a15cdac8ce9a02b8",
            "cd62b938582f4e6ba1ab062fa443394e",
            "735d5ceba60749e7be16b8af581a0b04",
            "6e2c49710577414d8db017a654d2e776",
            "99f24fda6d8c44f7a079dfa58eecaba9",
            "5bffca420d6c47c5aaa3a3e2e5e27641",
            "4dbc5c2169584eff915acca7e9cf8e81",
            "c6c59542e7fe48e98acf250d14f74150",
            "f75dc5bc7ed947219bb83dbed04791c3",
            "345ecc59a2ed4b64a81461af52bdf758"
          ]
        },
        "outputId": "66c35ca0-f988-468e-87f4-6382d01b9cc6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c14ab21ac454a20915a8582d6c1d3ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:562: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY = 0.0000\n"
          ]
        }
      ],
      "source": [
        "# Merge the LoRA weights into the main model\n",
        "trained_model = lora_model.merge_and_unload()\n",
        "trained_model\n",
        "\n",
        "evaluate(trained_model, my_prompt, testing_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.3 Troubleshoot: Combined Evaluation Metric\n",
        "\n",
        "The evaluation function gave an accuracy of 0.0000 with testing dataset (before and after PEFT finetuning), it indicates that the model's generated answers did not exactly match the reference answers. This could happen due to variations in wording, phrasing, or other factors in the output text. Even if the model's outputs are not exact matches (low accuracy), they may still be close in terms of BLEU score or maintain the intended sentiment, giving credit where due.\n",
        "\n",
        "Thus, I am using 'evaluate_final_score' as it may be more appropriate as it accounts for partial correctness and overall sentiment, offering a broader perspective on the model's performance.\n"
      ],
      "metadata": {
        "id": "AOBcqMzdJt0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import copy\n",
        "from tqdm.notebook import tqdm\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from textblob import TextBlob\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "s4tjZO8o2yIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_0fXghGihm7o"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_final_score(model, messages, testing_dataset, batch_size=16):\n",
        "    \"\"\"\n",
        "    Evaluate the model's performance on the testing dataset using accuracy, BLEU score, and sentiment score.\n",
        "    Compute a final score as the average of these three metrics.\n",
        "\n",
        "    Args:\n",
        "        model: The pre-trained language model.\n",
        "        messages: The prompt template in the OpenAI message format.\n",
        "        testing_dataset: The dataset containing Q&A pairs for testing.\n",
        "        batch_size: The number of examples to process in a batch.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing accuracy, average BLEU score, average sentiment score, and final score.\n",
        "    \"\"\"\n",
        "    num_correct = 0\n",
        "    bleu_scores = []\n",
        "    sentiment_scores = []\n",
        "\n",
        "    # Extract the questions and answers as lists\n",
        "    questions = testing_dataset['Question'].tolist()\n",
        "    answers = testing_dataset['Answer'].tolist()\n",
        "\n",
        "    # Create batches manually\n",
        "    for i in tqdm(range(0, len(questions), batch_size)):\n",
        "        batch_questions = questions[i:i + batch_size]\n",
        "        batch_answers = answers[i:i + batch_size]\n",
        "\n",
        "        # Generate responses in batch\n",
        "        batch_inputs = []\n",
        "        for question in batch_questions:\n",
        "            populated_messages = copy.deepcopy(messages)\n",
        "            for msg in populated_messages:\n",
        "                msg[\"content\"] = msg[\"content\"].replace(\"{SOURCE}\", question)\n",
        "\n",
        "            prompt_text = \" \".join([msg[\"content\"] for msg in populated_messages])\n",
        "            batch_inputs.append(prompt_text)\n",
        "\n",
        "        # Tokenize the batch input\n",
        "        inputs = tokenizer(batch_inputs, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
        "\n",
        "        # Generate outputs in batch\n",
        "        outputs = model.generate(inputs[\"input_ids\"], max_new_tokens=20, do_sample=False)\n",
        "\n",
        "        # Decode outputs and calculate metrics\n",
        "        for output_text, answer in zip(outputs, batch_answers):\n",
        "            output_text = tokenizer.decode(output_text, skip_special_tokens=True).strip().lower()\n",
        "            reference_answer = answer.strip().lower()\n",
        "\n",
        "            # Accuracy\n",
        "            if output_text == reference_answer:\n",
        "                num_correct += 1\n",
        "\n",
        "            # BLEU Score\n",
        "            bleu_score = sentence_bleu([reference_answer.split()], output_text.split())\n",
        "            bleu_scores.append(bleu_score)\n",
        "\n",
        "            # Sentiment Score\n",
        "            sentiment_score = TextBlob(output_text).sentiment.polarity\n",
        "            sentiment_scores.append(sentiment_score)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = num_correct / len(testing_dataset)\n",
        "    avg_bleu_score = np.mean(bleu_scores)\n",
        "    avg_sentiment_score = np.mean(sentiment_scores)\n",
        "\n",
        "    # Compute the final score as the average of accuracy, BLEU score, and sentiment score\n",
        "    final_score = np.mean([accuracy, avg_bleu_score, avg_sentiment_score])\n",
        "\n",
        "    print(f\"ACCURACY = {accuracy:.4f}\")\n",
        "    print(f\"AVERAGE BLEU SCORE = {avg_bleu_score:.4f}\")\n",
        "    print(f\"AVERAGE SENTIMENT SCORE = {avg_sentiment_score:.4f}\")\n",
        "    print(f\"FINAL SCORE = {final_score:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"avg_bleu_score\": avg_bleu_score,\n",
        "        \"avg_sentiment_score\": avg_sentiment_score,\n",
        "        \"final_score\": final_score,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the evaluation\n",
        "evaluate_final_score(model, my_prompt, testing_dataset)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "print(f\"Average BLEU Score: {metrics['avg_bleu_score']:.4f}\")\n",
        "print(f\"Average Sentiment Score: {metrics['avg_sentiment_score']:.4f}\")\n",
        "print(f\"Final Score: {metrics['final_score']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500,
          "referenced_widgets": [
            "042f9d5311ff4aa3b83f7c95c6083e08",
            "1a3c85f9874648a2acd6a1256ea9151d",
            "21b6d5922c4f45a3b67c4035e4c29cdf",
            "a736112575c3462b99cd52b858831ec7",
            "4e756324a0754b648c1421ff00a13bd6",
            "e91d65e91ec14344a109e1288f37c041",
            "52db344ce1214d499d579a37972b1e14",
            "08c4c0add73e49878a5d60694cea6486",
            "c7dc3f1bbd9b439183ebe018f5ec1892",
            "e39aa5916951415bb7ed3dc981064c48",
            "0fd3bfb4e714472fbe32a1e15c13865e"
          ]
        },
        "id": "7bYVPMKDv4Zs",
        "outputId": "ba051104-9fbf-488e-e36e-fe8660bccf67"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "042f9d5311ff4aa3b83f7c95c6083e08"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY = 0.0000\n",
            "AVERAGE BLEU SCORE = 0.0004\n",
            "AVERAGE SENTIMENT SCORE = 0.0321\n",
            "FINAL SCORE = 0.0109\n",
            "Accuracy: 0.0000\n",
            "Average BLEU Score: 0.0004\n",
            "Average Sentiment Score: 0.0321\n",
            "Final Score: 0.0109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "evaluate_final_score(lora_model, my_prompt, testing_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676,
          "referenced_widgets": [
            "8c3b0f91e9a14ba5b60dae532557315b",
            "c3ac1ff3c088420fbb3b88a0a9bbe030",
            "d80b470797724940b754d3605ef58f34",
            "05486e925a7e4fc585b7aa0e0e828ba7",
            "4855514460e6428789ba1058bbf38599",
            "bde5d60e4b47467fa97f9eb0096709aa",
            "5623adb65d43447690782cc6b12e3321",
            "d38223171e224b2fbed0b63aa60ada6b",
            "8bae50ea5046438c9065406965b0b4ea",
            "f8804f8ee45a48c69c0372afedb74061",
            "f911afbb260e4cf6be7ed20f9683d485"
          ]
        },
        "id": "QJo_NeYTJN3X",
        "outputId": "cbf9e462-71c7-4c6b-b8b5-1f19a48e4d4c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c3b0f91e9a14ba5b60dae532557315b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:562: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY = 0.0000\n",
            "AVERAGE BLEU SCORE = 0.0161\n",
            "AVERAGE SENTIMENT SCORE = 0.1404\n",
            "FINAL SCORE = 0.0522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion**\n",
        "\n",
        "The LoRA model shows improvements in BLEU score and sentiment score, including final score, These results suggest that LoRA fine-tuning enhanced the model's output quality. However, exact matches (accuracy) are still challenging. For both models, the accuracy remains at 0.0000, indicating that neither model generated exact matches with the reference answers."
      ],
      "metadata": {
        "id": "LqwEsgBw3YIz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3VaWq5vm_Q6"
      },
      "source": [
        "# **5. Chatbot Interface**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUyprEnQKKpE",
        "outputId": "a8955324-fcb5-4980-81c6-e17033bbaf95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.41.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.112.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio)\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.5)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.5.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.5-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-4.41.0-py3-none-any.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading ruff-0.5.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.5-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.112.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, orjson, ffmpy, aiofiles, starlette, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.0\n",
            "    Uninstalling tomlkit-0.13.0:\n",
            "      Successfully uninstalled tomlkit-0.13.0\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.112.0 ffmpy-0.4.0 gradio-4.41.0 gradio-client-1.3.0 orjson-3.10.6 pydub-0.25.1 python-multipart-0.0.9 ruff-0.5.7 semantic-version-2.10.0 starlette-0.37.2 tomlkit-0.12.0 uvicorn-0.30.5 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "n3XBcPNCy_qw",
        "outputId": "86e98d15-eb13-4330-a8eb-431b1157b6e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://ad5b295b3965b9de1e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://ad5b295b3965b9de1e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataframe (assuming you have already saved it)\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/faqs.csv')\n",
        "\n",
        "# Function to get answer from the dataframe based on the question\n",
        "def get_answer_from_df(question, df):\n",
        "    for idx, row in df.iterrows():\n",
        "        if row['Question'].strip().lower() == question.strip().lower():\n",
        "            return row['Answer']\n",
        "    return \"Sorry, I don't have an answer for that question.\"\n",
        "\n",
        "# Define the chatbot function\n",
        "def chatbot(message, history):\n",
        "    response = get_answer_from_df(message, df)\n",
        "    history.append((message, response))\n",
        "    return history\n",
        "\n",
        "# Define a testing function to ensure chatbot is working\n",
        "def slow_echo(message, history):\n",
        "    for i in range(len(message)):\n",
        "        time.sleep(0.3)\n",
        "        yield \"You typed: \" + message[: i+1]\n",
        "\n",
        "# Launch the chatbot using Gradio\n",
        "# gr.ChatInterface(chatbot).launch()\n",
        "gr.ChatInterface(slow_echo).launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "If-X4J8n-Lo2",
        "outputId": "c6526564-0799-40a3-f99e-f79668753279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://a0178161f7e33c0f5a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://a0178161f7e33c0f5a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataframe (assuming you have already saved it)\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/faqs.csv')\n",
        "\n",
        "# Function to get answer from the dataframe based on the question\n",
        "def get_answer_from_df(question, df):\n",
        "    for idx, row in df.iterrows():\n",
        "        if row['Question'].strip().lower() == question.strip().lower():\n",
        "            return row['Answer']\n",
        "    return \"Sorry, I don't have an answer for that question.\"\n",
        "\n",
        "# Define the chatbot function\n",
        "def chatbot(message, history):\n",
        "    response = get_answer_from_df(message, df)\n",
        "    history = history or []  # Initialize history if it's None\n",
        "    history.append((message, response))\n",
        "    return history\n",
        "\n",
        "# Launch the chatbot using Gradio\n",
        "gr.ChatInterface(fn=chatbot).launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQrR-Hwc2Ga3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1-dVHKR2GYL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eOIwg1f2GU3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3H_Cxw4L2GRk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJi6i9pF2GFY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ea059d87a7d744528b8c028c8051ec0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b61ee67592d4298a9c5dbd3ef5f6875",
              "IPY_MODEL_23394c9f675d4463bfc03e16fa7b1128",
              "IPY_MODEL_5e81d2ecedb149e4809374e1889eab8a"
            ],
            "layout": "IPY_MODEL_d9be35c8756441b9ac360161b2e618b8"
          }
        },
        "7b61ee67592d4298a9c5dbd3ef5f6875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a8d7767302c4935b00833ceb70e77e0",
            "placeholder": "​",
            "style": "IPY_MODEL_dc2aa52ad5364afcbb5ebba1e8bad55c",
            "value": "100%"
          }
        },
        "23394c9f675d4463bfc03e16fa7b1128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4098c58cbce45799c77f651d4c892d7",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8a104bc894541e789bd174d02e28819",
            "value": 7
          }
        },
        "5e81d2ecedb149e4809374e1889eab8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e43870a697145efa3188d4565726c69",
            "placeholder": "​",
            "style": "IPY_MODEL_d5d84a6597a9461abdfb645e88146fc0",
            "value": " 7/7 [02:10&lt;00:00, 15.52s/it]"
          }
        },
        "d9be35c8756441b9ac360161b2e618b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a8d7767302c4935b00833ceb70e77e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc2aa52ad5364afcbb5ebba1e8bad55c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4098c58cbce45799c77f651d4c892d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8a104bc894541e789bd174d02e28819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e43870a697145efa3188d4565726c69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5d84a6597a9461abdfb645e88146fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55c5d22e595d432cb2f8b3234df5bd01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f73e6937bc3406cb395091b6afbc74d",
              "IPY_MODEL_48032b38279448f6a99477e24791b139",
              "IPY_MODEL_aa90b5291b4e4cfca7120c90b0b5f631"
            ],
            "layout": "IPY_MODEL_2ab7836c1e024a73b009468696c707f0"
          }
        },
        "6f73e6937bc3406cb395091b6afbc74d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67edad20c98143aaa7f00b551413a6d8",
            "placeholder": "​",
            "style": "IPY_MODEL_d6212a17531e4eeb85ee178956c58d2d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "48032b38279448f6a99477e24791b139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d24a3447c2a64a90932762cc4ffc2452",
            "max": 2324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d337ec13ab4b4356af8e99b59a7c67da",
            "value": 2324
          }
        },
        "aa90b5291b4e4cfca7120c90b0b5f631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_007b48275b0f4a77a71e183b1fe7aaa8",
            "placeholder": "​",
            "style": "IPY_MODEL_4fd933dee71c4f00964ec8b869439341",
            "value": " 2.32k/2.32k [00:00&lt;00:00, 140kB/s]"
          }
        },
        "2ab7836c1e024a73b009468696c707f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67edad20c98143aaa7f00b551413a6d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6212a17531e4eeb85ee178956c58d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d24a3447c2a64a90932762cc4ffc2452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d337ec13ab4b4356af8e99b59a7c67da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "007b48275b0f4a77a71e183b1fe7aaa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fd933dee71c4f00964ec8b869439341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e898a10d7b84a4fb0007823d16a1fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6cd15d64cb874dcab23182ab110e661f",
              "IPY_MODEL_a782464d50894873bac3f80da6bbcaa8",
              "IPY_MODEL_1645116cf4724d08b0a14c11274892f9"
            ],
            "layout": "IPY_MODEL_6b23ee290e6d45ab8cbf85a16336dab4"
          }
        },
        "6cd15d64cb874dcab23182ab110e661f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f5f757a294546bfbd52657d8730d209",
            "placeholder": "​",
            "style": "IPY_MODEL_ebbb4148fefb46bf805d8ca0cb93bb7a",
            "value": "spiece.model: 100%"
          }
        },
        "a782464d50894873bac3f80da6bbcaa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9edda139a7c94ccd9c902fb07c9cce8f",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_794de245e7834191b1aec0d8d331e5f4",
            "value": 791656
          }
        },
        "1645116cf4724d08b0a14c11274892f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_546aba40645c4d859ba8055d040581ef",
            "placeholder": "​",
            "style": "IPY_MODEL_4d59afcb590b4b8a96f3610c741573a1",
            "value": " 792k/792k [00:00&lt;00:00, 10.4MB/s]"
          }
        },
        "6b23ee290e6d45ab8cbf85a16336dab4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f5f757a294546bfbd52657d8730d209": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebbb4148fefb46bf805d8ca0cb93bb7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9edda139a7c94ccd9c902fb07c9cce8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "794de245e7834191b1aec0d8d331e5f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "546aba40645c4d859ba8055d040581ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d59afcb590b4b8a96f3610c741573a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7174d0264c4649c29e234231bdba4cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b8ccfbd63d54179b15b82812e8b82de",
              "IPY_MODEL_7c715000e5d040b59fceec0df000ca2d",
              "IPY_MODEL_54c5d8115cec42af85539eb543672b4b"
            ],
            "layout": "IPY_MODEL_1a03bc52654745308f2cefbe253a8118"
          }
        },
        "5b8ccfbd63d54179b15b82812e8b82de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebe3de577ab7456ea8eff100dc4309bf",
            "placeholder": "​",
            "style": "IPY_MODEL_a98cda6f915547af8a2ac8b5482bd43d",
            "value": "tokenizer.json: 100%"
          }
        },
        "7c715000e5d040b59fceec0df000ca2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d30b88648f2496db621d47e28211764",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad2f92ad8e854acc99e50e249fce50a4",
            "value": 1389353
          }
        },
        "54c5d8115cec42af85539eb543672b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1af33672b37c403b8b8d9e13ffa36969",
            "placeholder": "​",
            "style": "IPY_MODEL_1fea98175981449caf5060fa7a05536a",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 27.3MB/s]"
          }
        },
        "1a03bc52654745308f2cefbe253a8118": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebe3de577ab7456ea8eff100dc4309bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a98cda6f915547af8a2ac8b5482bd43d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d30b88648f2496db621d47e28211764": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad2f92ad8e854acc99e50e249fce50a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1af33672b37c403b8b8d9e13ffa36969": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fea98175981449caf5060fa7a05536a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5b8774aa38f4f78b394bc6151f323fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f8ae87c486f440287cea7a3edade9ab",
              "IPY_MODEL_fedfaf60bb914070847d5c8fe56c76e2",
              "IPY_MODEL_66259998c63a46bea51ae3ef18dadc43"
            ],
            "layout": "IPY_MODEL_c8850a827993408d99b7087809b1fadd"
          }
        },
        "8f8ae87c486f440287cea7a3edade9ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11c9a02f6f374ab59e8a3d5483851333",
            "placeholder": "​",
            "style": "IPY_MODEL_5ac5851d002740a4948c177868010bc0",
            "value": "config.json: 100%"
          }
        },
        "fedfaf60bb914070847d5c8fe56c76e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc1a51f1b3b4490dabd79f328d06c2a6",
            "max": 1206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a70aefef4dba4035815c96d60109c9d2",
            "value": 1206
          }
        },
        "66259998c63a46bea51ae3ef18dadc43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef700574df334882a71ed2d8fe05c5d8",
            "placeholder": "​",
            "style": "IPY_MODEL_13e0a1b1b2734e578c699ab6ccfafbb2",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 53.2kB/s]"
          }
        },
        "c8850a827993408d99b7087809b1fadd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11c9a02f6f374ab59e8a3d5483851333": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ac5851d002740a4948c177868010bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc1a51f1b3b4490dabd79f328d06c2a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a70aefef4dba4035815c96d60109c9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef700574df334882a71ed2d8fe05c5d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13e0a1b1b2734e578c699ab6ccfafbb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e06c7a55948f47db88365d7b42dddd2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1494d897293e48008b7ce4014a198520",
              "IPY_MODEL_41a987492c6140ebab4a86d9df56c789",
              "IPY_MODEL_d9917034849940d6813813d30f495d84"
            ],
            "layout": "IPY_MODEL_1bdd22badc4345debf2ebddfc847eddd"
          }
        },
        "1494d897293e48008b7ce4014a198520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0675a1af46f545c7a6196736f010f9e8",
            "placeholder": "​",
            "style": "IPY_MODEL_8750d466fa5c464b88e5f82e096fc92a",
            "value": "model.safetensors: 100%"
          }
        },
        "41a987492c6140ebab4a86d9df56c789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_172edb1d55834ac08d2158db31298966",
            "max": 242043056,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_803885c5984f4b05a71bf17ba577706e",
            "value": 242043056
          }
        },
        "d9917034849940d6813813d30f495d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dbb811de37b4fa0aa88e248d6191d31",
            "placeholder": "​",
            "style": "IPY_MODEL_8e1f4b21a6a1474c94ede4483a2e3aac",
            "value": " 242M/242M [00:03&lt;00:00, 100MB/s]"
          }
        },
        "1bdd22badc4345debf2ebddfc847eddd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0675a1af46f545c7a6196736f010f9e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8750d466fa5c464b88e5f82e096fc92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "172edb1d55834ac08d2158db31298966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "803885c5984f4b05a71bf17ba577706e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2dbb811de37b4fa0aa88e248d6191d31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e1f4b21a6a1474c94ede4483a2e3aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c15df9ee7b146e082d2d756eb0ac8e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5680503786e04514911b085a74410ce8",
              "IPY_MODEL_85cf719ce7be40b89564a1022504c260",
              "IPY_MODEL_de02da7efaab425788a2c41662eb7de4"
            ],
            "layout": "IPY_MODEL_09ca5e1c9aa64ab5b67429819aed5b9b"
          }
        },
        "5680503786e04514911b085a74410ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_876966c998564bf08422dbdbe2adc85f",
            "placeholder": "​",
            "style": "IPY_MODEL_43b018835dfa483a8141baf9c55108ea",
            "value": "generation_config.json: 100%"
          }
        },
        "85cf719ce7be40b89564a1022504c260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d355742c2de49f6aa030497125aefe8",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52854316e2674f33a8c69e1d9a517b14",
            "value": 147
          }
        },
        "de02da7efaab425788a2c41662eb7de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bccc139beb346a68198033b6d51d00c",
            "placeholder": "​",
            "style": "IPY_MODEL_b2d2c8c1692c4a9fafea1a46c1948c74",
            "value": " 147/147 [00:00&lt;00:00, 2.01kB/s]"
          }
        },
        "09ca5e1c9aa64ab5b67429819aed5b9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "876966c998564bf08422dbdbe2adc85f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43b018835dfa483a8141baf9c55108ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d355742c2de49f6aa030497125aefe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52854316e2674f33a8c69e1d9a517b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bccc139beb346a68198033b6d51d00c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2d2c8c1692c4a9fafea1a46c1948c74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5eb376b45d840ad88bf70a62153d10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dba1afe4d8274b18afeb44e5e118753b",
              "IPY_MODEL_7f4d13b359cb4fe8bd6535d63e44631f",
              "IPY_MODEL_3f9216bd6e8e4cddbb9135a42dca1bb4"
            ],
            "layout": "IPY_MODEL_5ab8e4ed5c6f415b8150124d25525e9d"
          }
        },
        "dba1afe4d8274b18afeb44e5e118753b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e45044babb534634b81841ad24b8111d",
            "placeholder": "​",
            "style": "IPY_MODEL_82ecb7ac898443f78a6de8fb10fc97bc",
            "value": "100%"
          }
        },
        "7f4d13b359cb4fe8bd6535d63e44631f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2178291276f044bdbf0356672f5f2e90",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d026236eecdd40c88210743925c8728b",
            "value": 7
          }
        },
        "3f9216bd6e8e4cddbb9135a42dca1bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_485ec8fc10f64cf684bf65545722ee8f",
            "placeholder": "​",
            "style": "IPY_MODEL_cf0772c8aabe44888afd2132451a97d9",
            "value": " 7/7 [42:34&lt;00:00, 306.73s/it]"
          }
        },
        "5ab8e4ed5c6f415b8150124d25525e9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e45044babb534634b81841ad24b8111d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82ecb7ac898443f78a6de8fb10fc97bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2178291276f044bdbf0356672f5f2e90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d026236eecdd40c88210743925c8728b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "485ec8fc10f64cf684bf65545722ee8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf0772c8aabe44888afd2132451a97d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c14ab21ac454a20915a8582d6c1d3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5eaecfff2084b86a15cdac8ce9a02b8",
              "IPY_MODEL_cd62b938582f4e6ba1ab062fa443394e",
              "IPY_MODEL_735d5ceba60749e7be16b8af581a0b04"
            ],
            "layout": "IPY_MODEL_6e2c49710577414d8db017a654d2e776"
          }
        },
        "a5eaecfff2084b86a15cdac8ce9a02b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99f24fda6d8c44f7a079dfa58eecaba9",
            "placeholder": "​",
            "style": "IPY_MODEL_5bffca420d6c47c5aaa3a3e2e5e27641",
            "value": "100%"
          }
        },
        "cd62b938582f4e6ba1ab062fa443394e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dbc5c2169584eff915acca7e9cf8e81",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6c59542e7fe48e98acf250d14f74150",
            "value": 7
          }
        },
        "735d5ceba60749e7be16b8af581a0b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f75dc5bc7ed947219bb83dbed04791c3",
            "placeholder": "​",
            "style": "IPY_MODEL_345ecc59a2ed4b64a81461af52bdf758",
            "value": " 7/7 [45:15&lt;00:00, 317.53s/it]"
          }
        },
        "6e2c49710577414d8db017a654d2e776": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99f24fda6d8c44f7a079dfa58eecaba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bffca420d6c47c5aaa3a3e2e5e27641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dbc5c2169584eff915acca7e9cf8e81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6c59542e7fe48e98acf250d14f74150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f75dc5bc7ed947219bb83dbed04791c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "345ecc59a2ed4b64a81461af52bdf758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "042f9d5311ff4aa3b83f7c95c6083e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a3c85f9874648a2acd6a1256ea9151d",
              "IPY_MODEL_21b6d5922c4f45a3b67c4035e4c29cdf",
              "IPY_MODEL_a736112575c3462b99cd52b858831ec7"
            ],
            "layout": "IPY_MODEL_4e756324a0754b648c1421ff00a13bd6"
          }
        },
        "1a3c85f9874648a2acd6a1256ea9151d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e91d65e91ec14344a109e1288f37c041",
            "placeholder": "​",
            "style": "IPY_MODEL_52db344ce1214d499d579a37972b1e14",
            "value": "100%"
          }
        },
        "21b6d5922c4f45a3b67c4035e4c29cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08c4c0add73e49878a5d60694cea6486",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7dc3f1bbd9b439183ebe018f5ec1892",
            "value": 7
          }
        },
        "a736112575c3462b99cd52b858831ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e39aa5916951415bb7ed3dc981064c48",
            "placeholder": "​",
            "style": "IPY_MODEL_0fd3bfb4e714472fbe32a1e15c13865e",
            "value": " 7/7 [00:13&lt;00:00,  1.74s/it]"
          }
        },
        "4e756324a0754b648c1421ff00a13bd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e91d65e91ec14344a109e1288f37c041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52db344ce1214d499d579a37972b1e14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08c4c0add73e49878a5d60694cea6486": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7dc3f1bbd9b439183ebe018f5ec1892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e39aa5916951415bb7ed3dc981064c48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fd3bfb4e714472fbe32a1e15c13865e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c3b0f91e9a14ba5b60dae532557315b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3ac1ff3c088420fbb3b88a0a9bbe030",
              "IPY_MODEL_d80b470797724940b754d3605ef58f34",
              "IPY_MODEL_05486e925a7e4fc585b7aa0e0e828ba7"
            ],
            "layout": "IPY_MODEL_4855514460e6428789ba1058bbf38599"
          }
        },
        "c3ac1ff3c088420fbb3b88a0a9bbe030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bde5d60e4b47467fa97f9eb0096709aa",
            "placeholder": "​",
            "style": "IPY_MODEL_5623adb65d43447690782cc6b12e3321",
            "value": "100%"
          }
        },
        "d80b470797724940b754d3605ef58f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d38223171e224b2fbed0b63aa60ada6b",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8bae50ea5046438c9065406965b0b4ea",
            "value": 7
          }
        },
        "05486e925a7e4fc585b7aa0e0e828ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8804f8ee45a48c69c0372afedb74061",
            "placeholder": "​",
            "style": "IPY_MODEL_f911afbb260e4cf6be7ed20f9683d485",
            "value": " 7/7 [41:34&lt;00:00, 300.39s/it]"
          }
        },
        "4855514460e6428789ba1058bbf38599": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bde5d60e4b47467fa97f9eb0096709aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5623adb65d43447690782cc6b12e3321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d38223171e224b2fbed0b63aa60ada6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bae50ea5046438c9065406965b0b4ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8804f8ee45a48c69c0372afedb74061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f911afbb260e4cf6be7ed20f9683d485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}